{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IV Load the data for a station and organize for precipitation model\n",
    "#Check for update\n",
    "import os as os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import datetime\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths\n",
    "#Need to set up based on who is running\n",
    "usr = \"JH\"\n",
    "if usr == \"PK\":\n",
    "    #ipd01 = \"\\\\\\\\CXA01\\\\Users\\\\jhugh\\\\Documents\\\\HT\\\\NCEI_data\\\\2024\\\\\"\n",
    "    ipd02 = \"D:\\\\CodeLibrary\\\\Python\\\\weathermetrics\\\\data\\\\weathermetrics\\\\\"\n",
    "    ipd03 = \"\"\n",
    "    ipd04 = \"\"\n",
    "    \n",
    "if usr == \"JH\":\n",
    "    #ipd01 = \"\\\\\\\\CXA01\\\\Users\\\\jhugh\\\\Documents\\\\HT\\\\NCEI_data\\\\2024\\\\\"\n",
    "    ipd02 = \"\\\\\\\\CXA01\\\\Users\\\\jhugh\\\\Documents\\\\HT\\\\NCEI_data\\\\metrics_csv\\\\\"\n",
    "    ipd03 = \"\\\\\\\\CXA01\\\\Users\\\\jhugh\\\\Documents\\\\Py_S4\\\\NCEI_data\\\\\"\n",
    "    ipd04 = \"\\\\\\\\CXA01\\\\Users\\\\jhugh\\\\Documents\\\\Py_S4\\\\NCEI_parquet_files\\\\\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_select_data_vectors_pr07(stid_keys,nstations,nhours,nmonths_row,nmonths_col):\n",
    "    #Get the matrix of data to input into marix\n",
    "    #The S4 model\n",
    "    # 1. Read in combined data files for multiple stations\n",
    "    # 2. Find the common dates that will be used to align the matrices\n",
    "    #    Keep only the values that fit the common starting date \n",
    "\n",
    "    # 1. Read in data files and get start date v_date... for each\n",
    "    # Check that data exist for all metrics\n",
    "\n",
    "    df_stid = stid_keys\n",
    "    df_stid2 = df_stid.iloc[:, [0]]\n",
    "    df_stid2 = df_stid2.drop_duplicates() # unique()\n",
    "    \n",
    "    n_rows_stid = min(len(df_stid2),nstations)\n",
    "    #print(f\"n rows stid {n_rows_stid}\")\n",
    "    #Matrix in which measures are stored\n",
    "    n_vmt_rows = nhours*30*max(nmonths_row,nmonths_col)\n",
    "    \n",
    "    data_list = []\n",
    "    date_max_list =[]\n",
    "    \n",
    "    #1. Read in data files\n",
    "    for i in range(0, n_rows_stid):\n",
    "    #for i in range(0, 28):\n",
    "        infile = ipd03 + str(df_stid2.iloc[i,0]) #+ \"_model_data_combined.csv\"\n",
    "        print(infile)\n",
    "        \n",
    "        #Eliminate fully blank lines\n",
    "        cleaned_lines = []\n",
    "        with open(infile, 'r', newline='') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            for row in reader:\n",
    "                # Example: Skip rows that are entirely empty or have only blank 'name'\n",
    "                if any(cell.strip() for cell in row) and (len(row) < 1 or row[0].strip() != ''): # Assuming 'name' is the first column\n",
    "                    cleaned_lines.append(row)\n",
    "        \n",
    "        df_metrics = pd.DataFrame(cleaned_lines[1:], columns=cleaned_lines[0]) # Assuming first row is header\n",
    "\n",
    "        df_metrics['str_hr'] = df_metrics['nHOUR']  #.apply(lambda x: f'{x:02d}')\n",
    "        df_metrics['date_hr'] = pd.to_datetime(df_metrics['Date_YYYYMMDD'] + ' ' + df_metrics['str_hr'])\n",
    "        df_metrics['month_number'] = df_metrics['date_hr'].dt.month\n",
    "        df_metrics['week_number'] = df_metrics['date_hr'].dt.isocalendar().week\n",
    "        df_metrics['stid'] = str(df_stid2.iloc[i,0])\n",
    "        data_list.append(df_metrics)\n",
    "\n",
    "    #2. Align dates across data files\n",
    "    for i in range(0, n_rows_stid):\n",
    "        df = data_list[i]\n",
    "        max_date = max(df['date_hr'])     \n",
    "        date_max_list.append(max_date)\n",
    "    \n",
    "    date_filter = min(date_max_list)\n",
    "\n",
    "    for i in range(0, n_rows_stid):\n",
    "        df = data_list[i]\n",
    "\n",
    "        filtered_df = df[df['date_hr'] < date_filter]\n",
    "        filtered_df = filtered_df.iloc[(len(filtered_df) - n_vmt_rows):len(filtered_df)]\n",
    "        \n",
    "        idx_col = filtered_df.columns\n",
    "        idx_col = str(df_stid2.iloc[i,0]) + '_' + idx_col\n",
    "        filtered_df.columns = idx_col\n",
    "\n",
    "        print(filtered_df.shape)\n",
    "        \n",
    "        data_list[i] = filtered_df\n",
    "        \n",
    "    return data_list[0:n_rows_stid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_create_data_matrix_pr07(lst_data,tgt_metric,nstations,nmetrics,nmonths_col,ndays_col):\n",
    "    #Create a matrix for precipitation data that feeds\n",
    "    #The S4 model\n",
    "    # 1. Get data list and select target metric\n",
    "    #Two choices now\n",
    "    #    - prec\n",
    "    #    - temp\n",
    "    # 2.  Create output and move data into approprate cells\n",
    "\n",
    "    # 1. get data list details and reduce to metrics\n",
    "    data_vectors_list = []\n",
    "    dt_rows = len(lst_data[0])\n",
    "    df00 = []\n",
    "\n",
    "    dt_rows_minus_1 = dt_rows - 1\n",
    "    \n",
    "    if tgt_metric == \"prec\": tgt_cols = [10,2,3,4,5,6,8,9,11,12]\n",
    "    if tgt_metric == \"temp\": tgt_cols = [10,3,2,4,5,6,8,9,11,12]\n",
    "    non_metrics = 4  #These are the non sensor data brought in to analysis (e.g., day of year, month, ...)\n",
    "    \n",
    "    #Reset the indices as all records are ordered by date and hour\n",
    "    #But stations have missing records so not everything aligns\n",
    "    #Need to use the target station (station 0) as the standard and left join th other fields\n",
    "    print(f\"number of stations in data list {len(lst_data)}\")\n",
    "    n_data_files = len(lst_data)-1\n",
    "    \n",
    "    for i in range(n_data_files):\n",
    "        if i == 0:\n",
    "            tdt = lst_data[i].iloc[:,tgt_cols]\n",
    "        if i > 0:\n",
    "            tdt = lst_data[i].iloc[:,tgt_cols[0:6]]\n",
    "        tdt = tdt.iloc[::-1]\n",
    "        tdt.reset_index(drop=True, inplace=True)\n",
    "        first_column_name = tdt.columns[0]\n",
    "        tdt.rename(columns={first_column_name: 'key_date_hr'}, inplace=True)\n",
    "        #fn = f\"tdt data type {tdt['key_date_hr'].dtype}\"\n",
    "        #print(fn)\n",
    "        if tdt['key_date_hr'].dtype == \"datetime64[ns]\":\n",
    "            df00.append(tdt)\n",
    "            fn = f\"1. Done with setting up station -  {i}\"\n",
    "            #print(fn)\n",
    "    \n",
    "    \n",
    "    nstations_w_data = len(df00)\n",
    "    \n",
    "    #Take the list of station data, df00, and paste side by side\n",
    "    #to produce rs which is a large matrix of data for all stations \n",
    "    join_key = 'key_date_hr'\n",
    "    rs = reduce(lambda left, right: pd.merge(left, right, on=join_key, how='left'), df00)\n",
    "    \n",
    "    #rs has each row being a dayXhour for all stations for the stations full metrics\n",
    "    fn = f\"2. Shape of combined data including all stations\"\n",
    "    print(fn)\n",
    "    print(rs.shape)\n",
    "    \n",
    "\n",
    "    #2. Create output matrix and move data into appropriate cells\n",
    "    #Note: target cells get 9 elements, feature cells get 5 elements\n",
    "    \n",
    "    nmetrics_and_non_metrics = nmetrics + non_metrics\n",
    "    fn = f\"nmetrics_and_non_metrics {nmetrics_and_non_metrics}\"\n",
    "    print(fn)\n",
    "    #OLDndataelements = nmetrics_and_non_metrics + (nstations-1)*(nmetrics)\n",
    "    ndataelements = nmetrics_and_non_metrics + (nstations_w_data-1)*(nmetrics)\n",
    "    fn = f\"ndataelements - stations by metrics {ndataelements}\"\n",
    "    print(fn)\n",
    "    mt_cols = 1 + ndataelements*ndays_col*24\n",
    "    fn = f\"mt_cols 1 + #data elements*ndays_col*24 {mt_cols}\"\n",
    "    print(fn)\n",
    "    mt_rows = len(rs)\n",
    "    \n",
    "    #mt_rows = 170000  #keep here for development until done\n",
    "    mt_full_set = np.empty((mt_rows,mt_cols),np.float16)\n",
    "    \n",
    "    #Create matrix of data\n",
    "    for i in range(0,mt_rows):\n",
    "        mt_full_set[i,range(0,ndataelements)] = rs.iloc[i,range(1,ndataelements+1)].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    fn = f\"3. Full mt setup with initial data for the dayXhour only\"\n",
    "    print(fn)  \n",
    "    print(mt_full_set.shape)\n",
    "    \n",
    "    #Add additional column sets\n",
    "    lpi = mt_rows - ndays_col*24 - 1  #number of rows in rs matrix - the data elements in a column... \n",
    "                                      #ensures all records have data\n",
    "    \n",
    "    #limit of rows in data set so all matrix rows have data\n",
    "    lpj = ndays_col*24 -1   #number of colum sets to fill, each with 104 columns\n",
    "        \n",
    "    \n",
    "    #The row I am operating on\n",
    "    for i in range(0,lpi):\n",
    "        #The columns I am going to fill\n",
    "        for j in range(0,lpj):\n",
    "        \n",
    "            row_get = i + j + 1              #For every new column in current row we have to go down one more row\n",
    "            col_get_start = 0                #data retrieved starting column 1\n",
    "            col_get_end = ndataelements - 1\n",
    "            \n",
    "            row_put = i\n",
    "            col_put_start = ndataelements*(row_get - row_put)\n",
    "            col_put_end = col_put_start + ndataelements - 1\n",
    "            \n",
    "            mt_full_set[row_put,col_put_start:col_put_end] = mt_full_set[row_get,col_get_start:col_get_end]\n",
    "    \n",
    "    fn = f\"4. mt_full_set with ndays of data added to the columns\"\n",
    "    print(fn)  \n",
    "    print(mt_full_set.shape)\n",
    "    \n",
    "    return nstations_w_data, mt_full_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_create_data_matrix_DAY_SUMMARY(lst_data,tgt_metric,nstations,nmetrics,non_metrics,nmonths_col,ndays_col,ndays_to_target):\n",
    "    #Create a matrix for precipitation data that feeds\n",
    "    #The S4 model\n",
    "    # 1. Get data list and select target metric\n",
    "    #Two choices now\n",
    "    #    - prec\n",
    "    #    - temp\n",
    "    # 2.  Create output and move data into approprate cells\n",
    "    #print(\"HEREJHH\")\n",
    "    # 1. get data list details and reduce to metrics\n",
    "    data_vectors_list = []\n",
    "    dt_rows = len(lst_data[0])\n",
    "    df00 = []\n",
    "\n",
    "    dt_rows_minus_1 = dt_rows - 1\n",
    "    \n",
    "    if tgt_metric == \"prec\": \n",
    "        tgt_cols = [13,10,2,3,4,5,6]\n",
    "        ncol_names = ['station','key_date_hr','precip','airtemp','maxRH','relhum','minRH']\n",
    "    if tgt_metric == \"temp\": \n",
    "        tgt_cols = [13,10,3,2,4,5,6]\n",
    "        ncol_names = ['station','key_date_hr','airtemp','precip','maxRH','relhum','minRH']\n",
    "        \n",
    "    #Reset the indices as all records are ordered by date and hour\n",
    "    #But stations have missing records so not everything aligns\n",
    "    #Need to use the target station (station 0) as the standard and left join th other fields\n",
    "    print(f\"number of stations in data list {len(lst_data)}\")\n",
    "    n_data_files = min(len(lst_data)-1,nstations) #TB DELETE\n",
    "    n_data_files = min(len(lst_data),nstations)\n",
    "    #print(f\"n_data_files HERE {n_data_files}\")\n",
    "    \n",
    "    for i in range(n_data_files):\n",
    "        \n",
    "        tdt = lst_data[i].iloc[:,tgt_cols]\n",
    "        print(f\"tdt HERE {tdt}\")\n",
    "        tdt = tdt.iloc[::-1]  #Reverses row order\n",
    "        tdt.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        for j in range(len(tgt_cols)):\n",
    "            curr_column_name = tdt.columns[j]\n",
    "            tdt.rename(columns={curr_column_name: ncol_names[j]}, inplace=True)\n",
    "        \n",
    "        if tdt['key_date_hr'].dtype == \"datetime64[ns]\":\n",
    "            \n",
    "            tdt = tdt.set_index('key_date_hr')\n",
    "            tdt['precip'] = pd.to_numeric(tdt['precip'],errors='coerce')\n",
    "            tdt['precip'] = tdt['precip'].fillna(0)\n",
    "            tdt['precip_24hr_msum'] = tdt['precip'].rolling(window='24h').sum()\n",
    "            tdt['precip_24hr_mav'] = tdt['precip'].rolling(window='24h',min_periods=6).mean()\n",
    "            \n",
    "            tdt['airtemp'] = pd.to_numeric(tdt['airtemp'],errors='coerce')\n",
    "            tdt['airtemp_24hr_mav'] = tdt['airtemp'].rolling(window='24h',min_periods=6).mean()\n",
    "            \n",
    "            tdt['maxRH'] = pd.to_numeric(tdt['maxRH'],errors='coerce')\n",
    "            tdt['maxRH_24hr_mav'] = tdt['maxRH'].rolling(window='24h',min_periods=6).mean()\n",
    "    \n",
    "            tdt['relhum'] = pd.to_numeric(tdt['relhum'],errors='coerce')\n",
    "            tdt['relhum_24hr_mav'] = tdt['relhum'].rolling(window='24h',min_periods=6).mean()\n",
    "            \n",
    "            tdt['minRH'] = pd.to_numeric(tdt['minRH'],errors='coerce')\n",
    "            tdt['minRH_24hr_mav'] = tdt['minRH'].rolling(window='24h',min_periods=6).mean()        \n",
    "            \n",
    "            new_column_names = []\n",
    "            stri = str(i)\n",
    "            for n, col in enumerate(tdt.columns):\n",
    "                if i < 10: \n",
    "                    prefix = f\"st0{stri}_\"\n",
    "                    new_column_names.append(prefix + col)\n",
    "                \n",
    "                if i > 9: \n",
    "                    prefix = f\"st{stri}_\"\n",
    "                    new_column_names.append(prefix + col)\n",
    "\n",
    "            \n",
    "            #print(new_column_names)    \n",
    "            tdt.columns = new_column_names\n",
    "            df00.append(tdt)\n",
    "    \n",
    "    \n",
    "    df_valid_dates = pd.to_datetime(df00[0].index)\n",
    "    \n",
    "    print(f\"Number of valid rows: {len(df_valid_dates)}\")\n",
    "    \n",
    "    #Use a list comprehension to reindex each DataFrame, filling missing values with NaN.\n",
    "    df01 = [tdt.reindex(df_valid_dates) for tdt in df00]\n",
    "    df02 = [tdt.iloc[:,[0,6,7,8,9,10,11]] for tdt in df01]\n",
    "    \n",
    "    #Concatenate the reindexed DataFrames into a single DataFrame if needed.\n",
    "    rs = pd.concat(df02, axis=1)\n",
    "                \n",
    "    nstations_w_data = len(df02)\n",
    "    print(f\"Number of stations with data: {nstations_w_data}\")\n",
    "\n",
    "    fn = f\"2. Shape of combined data including all stations\"\n",
    "    print(fn)\n",
    "    print(rs.shape)\n",
    "    \n",
    "    #2. Create output matrix and move data into appropriate cells\n",
    "    #Note: target cells get 9 elements, feature cells get 5 elements\n",
    "    \n",
    "    nmetrics_and_non_metrics = nmetrics + non_metrics\n",
    "    fn = f\"nmetrics - {nmetrics_and_non_metrics}\"\n",
    "    print(fn)\n",
    "    \n",
    "    ndataelements = (nstations_w_data)*(nmetrics)\n",
    "    fn = f\"ndataelements - stations by metrics {ndataelements}\"\n",
    "    print(fn)\n",
    "    \n",
    "    rows_to_cols_sets = (ndays_col+ndays_to_target)*24\n",
    "    mt_cols = ndataelements*rows_to_cols_sets   #add two columns for the month and hour for the first set of data\n",
    "    fn = f\"mt_cols - ndataelements*(ndays_col+ndays_to_target)*24 {mt_cols}\"\n",
    "    print(fn)\n",
    "\n",
    "    #Identify the rows down to start\n",
    "\n",
    "    rows_to_include = len(df_valid_dates) - rows_to_cols_sets - 1\n",
    "    fn = f\"rows to include - len(df_valid_dates) - rows_to_cols_sets - 1 {rows_to_include}\"\n",
    "    print(fn)\n",
    "     \n",
    "    mt_full_set = np.empty((rows_to_include,mt_cols),np.float16)\n",
    "    fn = f\"mt_shape - {mt_full_set.shape}\"\n",
    "    print(fn)\n",
    "\n",
    "    ar_str_mon = np.array(rs.index.strftime('%m')).reshape(-1,1)\n",
    "    ar_str_mon = ar_str_mon[0:rows_to_include]\n",
    "    ar_str_hr = np.array(rs.index.strftime('%H')).reshape(-1,1)\n",
    "    ar_str_hr = ar_str_hr[0:rows_to_include]\n",
    "    rs.drop('st00_station', axis=1, inplace=True)\n",
    "    \n",
    "    #Create matrix of data\n",
    "    #rows_to_include = 1000  #number of col_rows to be copied each time from column A and placed in col B    \n",
    "    mt_loops = rows_to_cols_sets     #number of loops over which to copy each group of rows\n",
    "    \n",
    "    j = 0  #Loop across stations, set to operate only on the target station\n",
    "    for i in range(0,mt_loops):\n",
    "        mt_full_set[j:rows_to_include,range(i*nmetrics,i*nmetrics + nmetrics)] = rs.iloc[i:(i+rows_to_include),0:(nmetrics+1)].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    #Add date month and hour info and delete data too close\n",
    "    mt_full_set_rtn = np.concatenate((ar_str_mon,ar_str_hr,mt_full_set),axis=1)\n",
    "    \n",
    "    fn = f\"3. Full mt setup with initial data for the dayXhour only\"\n",
    "    print(fn)  \n",
    "    print(mt_full_set_rtn.shape)\n",
    "    ''''''\n",
    "    return mt_full_set_rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_create_tgt_matrix_pr07(mtx_data,tgt_metric,tgt_mod,nstations,nmetrics,ndays_col):\n",
    "    \n",
    "    mtx01 = mtx_data #.iloc[0:1000,:]\n",
    "    nrows = mtx01.shape[0]\n",
    "    ncols = mtx01.shape[1]\n",
    "    \n",
    "       \n",
    "    if tgt_metric == \"prec\" and tgt_mod == \"prec_ex01\": \n",
    "        rtn_matrix = fn_prec_ex01(mtx01,nstations,nmetrics,ndays_col)\n",
    "    \n",
    "    \n",
    "    #return the matrix for analysis\n",
    "    return rtn_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_create_DAY_SUMMARY_tgt_matrix_pr07(mtx_data,tgt_metric,tgt_mod,nstations,nmetrics,ndays_col,ndays_to_target):\n",
    "    \n",
    "    mtx01 = mtx_data  #.iloc[0:100000,:]\n",
    "    nrows = mtx01.shape[0]\n",
    "    ncols = mtx01.shape[1]\n",
    "    \n",
    "    if tgt_metric == \"prec\" and tgt_mod == \"prec_ex02\": \n",
    "        rtn_matrix = fn_prec_ex02(mtx01,1,nmetrics,ndays_col,ndays_to_target)\n",
    "    \n",
    "    return rtn_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_prec_ex01(mtx01,nstations,nmetrics,dayscol):\n",
    "    \n",
    "    df = pd.DataFrame(mtx01).reset_index(drop=True)\n",
    "    ncols_orig = df.shape[1]\n",
    "    print(f\"Number of mxt columns {ncols_orig}\")\n",
    "    \n",
    "    #Data come in as follows\n",
    "    #target station \n",
    "    #      - number of metrics (nmetrics)\n",
    "    #      - date columns (4)\n",
    "    #feat station 1  - number of metrics (nmetrics)\n",
    "    #feat station ...  - number of metrics (nmetrics)\n",
    "    #feat station nstations  - number of metrics (nmetrics)\n",
    "    #total columns = (nmetrics + date columns) + (nstations+nmetrics)\n",
    "    \n",
    "    offset = 4  #additional fields for target station\n",
    "    data_columns_start = (nmetrics + offset) + (nstations - 1)*nmetrics\n",
    "    print(f\"data_columns_start {data_columns_start}\")\n",
    "    \n",
    "    tot_per = dayscol*24  #days by 24 hours\n",
    "    \n",
    "    for iper in range(1,tot_per,1):\n",
    "\n",
    "        vc_start1 = np.array([(iper*nstations*(nmetrics) + (iper*offset))])\n",
    "        vc_start2 = vc_start1 + nmetrics + offset   #first set has day/month/week/hr info\n",
    "        vc_end = vc_start2 + (nstations-1)*nmetrics\n",
    "        vc_s2_end = np.arange(vc_start2.item(),vc_end.item(),nmetrics)\n",
    "        vc_num = np.concatenate([vc_start1,vc_s2_end])\n",
    "        \n",
    "        nm1 = 'avg'+ str(iper)\n",
    "        pds1 = df.iloc[:,vc_num].mean(axis=1,skipna=True)\n",
    "        df[nm1] = pds1\n",
    "        \n",
    "        nm2 = 'cnt_ge_zero'+ str(iper)\n",
    "        pds2 = df.iloc[:,vc_num].apply(cnt_ge0,axis=1)\n",
    "        df[nm2] = pds2\n",
    "        \n",
    "        nm3 = 'cnt_gt_zero'+ str(iper)\n",
    "        pds3 = df.iloc[:,vc_num].apply(cnt_gt0,axis=1)\n",
    "        df[nm3] = pds3\n",
    "               \n",
    "    ncols_final = df.shape[1]\n",
    "    print(f\"Final shape {ncols_final}\")\n",
    "    new_cols = range(ncols_orig,ncols_final,1)\n",
    "    print(f\"New columns {new_cols}\")\n",
    "    old_cols = range(data_columns_start,ncols_orig-1,1)\n",
    "    print(f\"Old columns {old_cols}\")\n",
    "    vc_keep = [0]+list(new_cols) + list(old_cols)\n",
    "    print(f\"Final columns {ncols_final}\")\n",
    "    \n",
    "    df.rename(columns={'0': 'tgt_precip', '5': 'day_of_year'\n",
    "                       , '6': 'hour_of_day'\n",
    "                       , '7': 'month_of_year'\n",
    "                       , '8': 'week_of_year'}, inplace=True)\n",
    "    \n",
    "    df_out = pd.concat([df.iloc[:,[0,5,7,8,6]],df.iloc[:,new_cols],df.iloc[:,old_cols]],axis=1)\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_prec_ex02(mtx01,nstations,nmetrics,dayscol,ndays_to_target):\n",
    "    \n",
    "    df = pd.DataFrame(mtx01).reset_index(drop=True)\n",
    "    ncols_orig = df.shape[1]\n",
    "    print(f\"Number of mxt columns {ncols_orig}\")\n",
    "    \n",
    "    #Data come in as follows\n",
    "    #target station\n",
    "    #      - date columns (2) Month Hour\n",
    "    #      - number of metrics (nmetrics)\n",
    "    #      - number of sets of day by hour (dayscol*24)\n",
    "    \n",
    "\n",
    "    data_columns_start = 2\n",
    "    tgt_column = 3   # precip sum   \n",
    "    tot_per = dayscol*24  #days by 24 hours\n",
    "    \n",
    "    cols = df.columns.tolist()\n",
    "    ncols = [cols[2],cols[0],cols[1]] + cols[3:]\n",
    "    #df_out = df.reindex(columns)\n",
    "    \n",
    "    dt_start = 3 + ndays_to_target*24\n",
    "    vc = [2,0,1] + list(range(dt_start,4754))\n",
    "    df_out = df.iloc[:,vc]\n",
    "    \n",
    "    df_out.rename(columns={'2': 'tgt_precip'\n",
    "                       , '1': 'hour_of_day'\n",
    "                       , '0': 'month_of_year'}, inplace=True)\n",
    "                       \n",
    "        \n",
    "    return df_out #new_order_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to identify stations in network that have rain sensor and rain\n",
    "def cnt_ge0(row):\n",
    "        cnt_gt_0 = sum(row >= 0)\n",
    "        return cnt_gt_0\n",
    "\n",
    "def cnt_gt0(row):\n",
    "        cnt_gt_0 = sum(row > 0)\n",
    "        return cnt_gt_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_get_nearby_stations(stid_target, target_file,in_wd):\n",
    "\n",
    "    dt01 = target_file[target_file['tgt_stid']==stid_target]\n",
    "    dt01 = dt01[['feat_stid','dist_km']]\n",
    "    vc_stid = dt01['feat_stid'].to_numpy()\n",
    "    \n",
    "    vc_stid = np.insert(vc_stid,0,stid_target)\n",
    "    \n",
    "    #Need to create more combined data sets\n",
    "    lst_files = os.listdir(in_wd)\n",
    "    df_files = pd.DataFrame(lst_files,columns=[\"files\"])\n",
    "    df_files['stid'] = df_files['files'].str[:11]\n",
    "    df_files['istarget'] = df_files['stid'].str.contains(stid_target,case=False)\n",
    "    df_files['file_type'] = df_files['files'].str[23:31]\n",
    "    df_files['isintarget'] = df_files['stid'].isin(vc_stid)\n",
    "    \n",
    "    df_files = df_files[df_files['file_type']==\"combined\"]\n",
    "    df_files = df_files[df_files['isintarget']==True]\n",
    "    \n",
    "    mrg_df = pd.merge(df_files, dt01,how='left',left_on='stid',right_on='feat_stid')\n",
    "    mrg_df = mrg_df.drop(columns=['feat_stid','isintarget','file_type'])\n",
    "    mrg_df = mrg_df.sort_values(by='dist_km',na_position='first')\n",
    "    mrg_df = mrg_df.reset_index(drop=True)\n",
    "    mrg_df.columns = ['fnames','st_id','is_target_station','dist_km']\n",
    "    \n",
    "    return mrg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_create_data_sets(tgt_stid):\n",
    "    \n",
    "    print(tgt_stid)\n",
    "    \n",
    "    #Select the target station for which predictions will be made\n",
    "    dt_trg_set2 = ipd02 + \"..\\\\Station_Pairs_LE_100km_Info.csv\"\n",
    "    dt_analysis_set2 = pd.read_csv(dt_trg_set2)\n",
    "\n",
    "    #Nearby stations within 100km\n",
    "    #dt_analysis_set_keys = fn_get_nearby_stations(tgt_stid,dt_analysis_set2,ipd03)\n",
    "    \n",
    "    dt_analysis_set_keys = dt_analysis_set2[dt_analysis_set2['tgt_stid'] == tgt_stid]    \n",
    "    print(f\"dt_analysis_set_keys{dt_analysis_set_keys}\")\n",
    "\n",
    "    dt_analysis_set_keys['fpn'] = ipd03 + dt_analysis_set_keys['feat_stid']+\"_model_data_combined.csv\"\n",
    "\n",
    "    dt_analysis_set_keys['file exists'] = dt_analysis_set_keys['fpn'].apply(lambda x: os.path.exists(x))\n",
    "\n",
    "    dt_analysis_set_keys = dt_analysis_set_keys[dt_analysis_set_keys['file exists'] == True]\n",
    "\n",
    "    nstations_in_100km = len(dt_analysis_set_keys) #number of stations within 100 km\n",
    "    num_st_keep = 20   #num of stations to keep for analysis\n",
    "    nstations = min(nstations_in_100km,num_st_keep)\n",
    "    \n",
    "    #Specify parameters governing the creation of data matrix for analysis\n",
    "    #All the available stations which have all three metrics needed for model\n",
    "    #vc_stid = dt_analysis_set_keys[['st_id']].drop_duplicates()\n",
    "\n",
    "    #Organize the data based on the nature of the data so they all conform to the same size matrices\n",
    "    #The metrics included are\n",
    "    #  AT - air temperature in Celcius\n",
    "    #  RH - relative humidity in Percent\n",
    "    #  PR - precipitation in MM\n",
    "\n",
    "    #Put them all in appropriate matrices and create list of metrics\n",
    "    #Data files are of two types\n",
    "    #    -  24 hour * 365 days * n years  (AT, PR)\n",
    "    #    -  365 days * n years (RH)\n",
    "    \n",
    "    #Parameters governing data matrix\n",
    "    stid_target = tgt_stid\n",
    "    stid_keys = dt_analysis_set_keys\n",
    "\n",
    "    #print(f\"st id keys{dt_analysis_set_keys}\")\n",
    "    \n",
    "    ipd = ipd02\n",
    "    nhours = 24\n",
    "    ndays = 365\n",
    "    nmonths_row = 240  #total months on rows of data\n",
    "    nmonths_col = 2 #governs the number of months predicting that are needed\n",
    "    ndays_col = 3  #governs the number of days predicting that are needed\n",
    "    nmetrics = 5  #number of metrics in the data file\n",
    "    tgt_metric =  \"prec\" #\"prec\" \"temp\"    the metric to be modeled\n",
    "    tgt_mod = \"prec_ex01\"  #specifies the metric specific approach for creating data set\n",
    "    \n",
    "    #1. Get the relevant station data and return in a list\n",
    "    lst_data = fn_select_data_vectors_pr07(stid_keys,nstations,nhours,nmonths_row,nmonths_col)\n",
    "    fn = f\"std id keys {stid_keys}\"\n",
    "    print(fn)\n",
    "    \n",
    "    #2. Construct a matrix from most recent to most distant data from the list data\n",
    "    nstations_w_data, mtx_data = fn_create_data_matrix_pr07(lst_data,tgt_metric,nstations,nmetrics,nmonths_col,ndays_col)\n",
    "    fn = f\"mtx data done\"\n",
    "    print(fn)\n",
    "    \n",
    "    #Save the mtx_data to a folder\n",
    "    #This lets us start at Step 3 for subsequent runs\n",
    "    print(ipd04)\n",
    "    rtn_mtx_pqt = pd.DataFrame(mtx_data)\n",
    "    print(rtn_mtx_pqt.shape)\n",
    "    fn = f\"{ipd04}{tgt_metric}_mtx_{stid_target}_stations_{nstations_w_data}_RowMn_{nmonths_row}_ColDy_{ndays_col}.parquet\"\n",
    "    print(fn)\n",
    "    rtn_mtx_pqt.to_parquet(fn, index=False)    \n",
    "    \n",
    "    #3.  Create a target variable, select feature variables, create data frame for input into s4 analysis\n",
    "    s4_data = fn_create_tgt_matrix_pr07(mtx_data,\"prec\",\"prec_ex01\",nstations_w_data,nmetrics,ndays_col)\n",
    "    \n",
    "    print(f\"Shape of s4_data {s4_data.shape}\")\n",
    "    fn = f\"s4 data done\"\n",
    "    print(fn)\n",
    "    \n",
    "    #4. Save the s4_data to a folder\n",
    "    #This lets us start at Step 4 for iterative runs\n",
    "\n",
    "    print(ipd04)\n",
    "    rtn_s4_data_pqt = pd.DataFrame(s4_data)\n",
    "    print(rtn_s4_data_pqt.shape)\n",
    "    fn = f\"{ipd04}{tgt_metric}_s4data_{stid_target}_stations_{nstations_w_data}_RowMn_{nmonths_row}_ColDy_{ndays_col}.parquet\"\n",
    "    print(fn)\n",
    "    rtn_s4_data_pqt.to_parquet(fn, index=False)    \n",
    "    \n",
    "    # Prep s4 data for modeling\n",
    "    # Example matrix (replace this with your actual matrix)\n",
    "    df = pd.DataFrame(s4_data).iloc[1:,] # Convert to DataFrame and drop the first row for binning\n",
    "    print(f\"All records at start {df.shape}\")\n",
    "    ##Only keep records w rain\n",
    "    #df = df[df.iloc[:,0]>0]\n",
    "    #print(df.shape)\n",
    "\n",
    "    #Drop rows where there has been no rain in total area for past 48 hours\n",
    "    ndays_check_for_rain = ndays_col\n",
    "    range_of_data = ndays_check_for_rain*ndays_col*(24) + ndays_col\n",
    "    vc_num = [x for x in range(5,range_of_data,3)]\n",
    "\n",
    "    nm1 = 'sum_avg'\n",
    "    pds1 = df.iloc[:,vc_num].sum(axis=1,skipna=True)\n",
    "    df_area_non_zero = df[pds1 > 0]\n",
    "    print(f\"Records with some rain in last {ndays_check_for_rain} days {df_area_non_zero.shape}\")\n",
    "\n",
    "    #Separate into dataframes with and withot rain in past n days\n",
    "    df_area_non_zero_yrain = df_area_non_zero[df_area_non_zero.iloc[:,0]>0]\n",
    "    df_area_non_zero_nrain = df_area_non_zero[df_area_non_zero.iloc[:,0]==0]\n",
    "\n",
    "    #sample non-rain to help balance outcomes if needed\n",
    "    df_sample_nrain = df_area_non_zero_nrain  #df_area_non_zero_nrain.sample(n=len(df_area_non_zero_yrain))\n",
    "    df_area_non_zero_ynrain = pd.concat((df_area_non_zero_yrain,df_sample_nrain),axis=0)\n",
    "\n",
    "    #Choose the df for analysis\n",
    "    dfs = df_area_non_zero_ynrain\n",
    "    print(f\"Full rain and no rain {dfs.shape}\")\n",
    "\n",
    "    del df, df_area_non_zero_yrain, df_area_non_zero_nrain, df_area_non_zero_ynrain\n",
    "    \n",
    "    # Drop rows where the first column has missing values\n",
    "    # df = df.dropna(subset=[0])\n",
    "    condition = np.isfinite(dfs.iloc[:,0])\n",
    "    df_subset = pd.DataFrame(dfs[condition])\n",
    "    del dfs\n",
    "    print(df_subset.shape)\n",
    "\n",
    "\n",
    "    bins = [-float('inf'),0.1,0.5,1,2,3,4,5,float('inf')]\n",
    "    labels = [0,0.1, 0.5,1,2,3,4,5]\n",
    "    print(bins, labels)\n",
    "\n",
    "    df_transformed = transform_matrix_precip(df_subset, bins, labels)\n",
    "\n",
    "    df_transformed.drop(columns=df_transformed.columns[1],inplace=True)\n",
    "    df_transformed.shape\n",
    "\n",
    "    df_transformed = df_transformed.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    print(\"Analysis Set:\", df_transformed.shape)\n",
    "\n",
    "    print(df_transformed['tgt_bin'].value_counts(dropna=False).sort_index())\n",
    "\n",
    "    train_data, val_data, test_data = split_time_series_data(df_transformed)\n",
    "    \n",
    "    train_data.to_parquet(f\"{ipd04}{stid_target}_train.parquet\", index=False)\n",
    "    val_data.to_parquet(f\"{ipd04}{stid_target}_validation.parquet\", index=False)\n",
    "    test_data.to_parquet(f\"{ipd04}{stid_target}_test.parquet\", index=False)\n",
    "\n",
    "    # code for saving to csv for testing and checking\n",
    "    # train_data.to_csv(f\"{ipd04}{stid_target}_train.csv\", index=False)\n",
    "    # val_data.to_csv(f\"{ipd04}{stid_target}_validation.csv\", index=False)\n",
    "    # test_data.to_csv(f\"{ipd04}{stid_target}_test.csv\", index=False)\n",
    "    \n",
    "    print(\"Datasets exported successfully.\") \n",
    "    \n",
    "    return 1 #mtx_data  #stid_keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#SETUP  Select a station using ID to get its related stations\n",
    "\n",
    "#Load df of target stations and those close by\n",
    "#74486094789 is JFK airport\n",
    "#74486454787 is Farmingdale\n",
    "#72502014734 is Newark\n",
    "#72427653859 is Dayton, OH\n",
    "#72551014939 is Lincoln, NE\n",
    "#72793024233 is Seattle, WA\n",
    "#72202012839 is Miami, FL\n",
    "#72202012839 is Miami, FL\n",
    "#72243012960 is Houston, TX\n",
    "#72572024127 is Salt Lake City, UT\n",
    "#72278023183 is Phoenix, AZ\n",
    "\n",
    "#76001399999 is Gen Abelardo Mexico\n",
    "#71413099999 is Spondin Canada\n",
    "#72507554768 is North Adams, US, ME\n",
    "#72614054742 is St Johnsbury, US, VT\n",
    "#72027312981 \n",
    "#72036363872 \n",
    "#74594693786 errors in data files\n",
    "#72027504872\n",
    "#72030553964\n",
    "#72037492825\n",
    "\n",
    "\n",
    "#Select the target station for which predictions will be made\n",
    "dt_trg_set2 = ipd02 + \"..\\\\Station_Pairs_LE_100km_Info.csv\"\n",
    "dt_analysis_set2 = pd.read_csv(dt_trg_set2)\n",
    "#Governs the target station in subsequent modules\n",
    "tgt_stid =  \"72037492825\"\n",
    "\n",
    "#Nearby stations within 100km\n",
    "dt_analysis_set_keys = fn_get_nearby_stations(tgt_stid,dt_analysis_set2,ipd03)\n",
    "\n",
    "nstations_in_100km = len(dt_analysis_set_keys) #number of stations within 100 km\n",
    "num_st_keep = 20   #num of stations to keep for analysis\n",
    "nstations = min(nstations_in_100km,num_st_keep)\n",
    "\n",
    "dt_analysis_set_keys\n",
    "\n",
    "#Specify parameters governing the creation of data matrix for analysis\n",
    "#All the available stations which have all three metrics needed for model\n",
    "#vc_stid = dt_analysis_set_keys[['st_id']].drop_duplicates()\n",
    "\n",
    "#Organize the data based on the nature of the data so they all conform to the same size matrices\n",
    "#The metrics included are\n",
    "#  AT - air temperature in Celcius\n",
    "#  RH - relative humidity in Percent\n",
    "#  PR - precipitation in MM\n",
    "\n",
    "#Put them all in appropriate matrices and create list of metrics\n",
    "#Data files are of two types\n",
    "#    -  24 hour * 365 days * n years  (AT, PR)\n",
    "#    -  365 days * n years (RH)\n",
    "\n",
    "#Parameters governing data matrix\n",
    "stid_target = tgt_stid\n",
    "stid_keys = dt_analysis_set_keys\n",
    "\n",
    "ipd = ipd02\n",
    "nhours = 24\n",
    "ndays = 365\n",
    "nmonths_row = 240  #total months on rows of data\n",
    "nmonths_col = 2 #governs the number of months predicting that are needed\n",
    "ndays_col = 3  #governs the number of days predicting that are needed\n",
    "nmetrics = 5  #number of metrics in the data file\n",
    "tgt_metric =  \"prec\" #\"prec\" \"temp\"    the metric to be modeled\n",
    "tgt_mod = \"prec_ex01\"  #specifies the metric specific approach for creating data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Get the relevant station data and return in a list a list\n",
    "lst_data = fn_select_data_vectors_pr07(stid_keys,nstations,nhours,nmonths_row,nmonths_col)\n",
    "fn = f\"lst data done\"\n",
    "print(fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#2. Construct a matrix from most recent to most distant data from the list data\n",
    "mtx_data = fn_create_data_matrix_pr07(lst_data,tgt_metric,nstations,nmetrics,nmonths_col,ndays_col)\n",
    "fn = f\"mtx data done\"\n",
    "print(fn)\n",
    "\n",
    "#Save the mtx_data to a folder\n",
    "#This lets us start at Step 3 for subsequent runs\n",
    "print(ipd04)\n",
    "rtn_mtx_pqt = pd.DataFrame(mtx_data)\n",
    "print(rtn_mtx_pqt.shape)\n",
    "fn = f\"{ipd04}{tgt_metric}_mtx_{stid_target}_stations_{nstations}_RowMn_{nmonths_row}_ColDy_{ndays_col}.parquet\"\n",
    "print(fn)\n",
    "rtn_mtx_pqt.to_parquet(fn, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fn = f\"{ipd04}{tgt_metric}_mtx_{stid_target}_stations_{nstations}_RowMn_{nmonths_row}_ColDy_{ndays_col}.parquet\"\n",
    "#fn = '\\\\\\\\CXA01\\\\Users\\\\jhugh\\\\Documents\\\\Py_S4\\\\Py_S4_v02_JHH\\\\NCEI_parquet_files\\\\prec_mtx_74486094789_stations_20_RowMn_240_ColDy_7.parquet'\n",
    "fn = \"\\\\\\\\CXA01\\\\Users\\\\jhugh\\\\Documents\\\\Py_S4\\\\NCEI_parquet_files\\\\my_data.parquet\"\n",
    "# Read the Parquet file into a Pandas DataFrame\n",
    "mtx_data = pd.read_parquet(fn)\n",
    "print(mtx_data.shape)\n",
    "mtx_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.  Read in mtx_data file\n",
    "\n",
    "#Get the mtx_data from a folder\n",
    "#This lets us start at Step 3 for iterative runs\n",
    "fn = f\"{ipd04}{tgt_metric}_mtx_{stid_target}_stations_{nstations}_RowMn_{nmonths_row}_ColDy_{ndays_col}.parquet\"\n",
    "#fn = '\\\\\\\\CXA01\\\\Users\\\\jhugh\\\\Documents\\\\Py_S4\\\\Py_S4_v02_JHH\\\\NCEI_parquet_files\\\\prec_mtx_74486094789_stations_20_RowMn_240_ColDy_7.parquet'\n",
    "\n",
    "# Read the Parquet file into a Pandas DataFrame\n",
    "mtx_data = pd.read_parquet(fn)\n",
    "print(mtx_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.  Create a target variable, select feature variables, create data frame for input into s4 analysis\n",
    "\n",
    "s4_data = fn_create_tgt_matrix_pr07(mtx_data,\"prec\",\"prec_ex01\",nstations,nmetrics,ndays_col)\n",
    "\n",
    "print(f\"Shape of s4_data {s4_data.shape}\")\n",
    "fn = f\"s4 data done\"\n",
    "print(fn)\n",
    "s4_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Save the s4_data to a folder\n",
    "#This lets us start at Step 4 for iterative runs\n",
    "\n",
    "print(ipd04)\n",
    "rtn_s4_data_pqt = pd.DataFrame(s4_data)\n",
    "print(rtn_s4_data_pqt.shape)\n",
    "fn = f\"{ipd04}{tgt_metric}_s4data_{stid_target}_stations_{nstations}_RowMn_{nmonths_row}_ColDy_{ndays_col}.parquet\"\n",
    "print(fn)\n",
    "rtn_s4_data_pqt.to_parquet(fn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This lets us start at Step 4 for iterative runs\n",
    "fn = f\"{ipd04}{tgt_metric}_s4data_{stid_target}_stations_{nstations}_RowMn_{nmonths_row}_ColDy_{ndays_col}.parquet\"\n",
    "print(fn)\n",
    "\n",
    "# Read the Parquet file into a Pandas DataFrame\n",
    "s4_data = pd.read_parquet(fn)\n",
    "print(s4_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_matrix_precip(df, bins, labels):\n",
    "    \"\"\"\n",
    "    Transforms the given matrix by binning the first column, dropping the first row and column,\n",
    "    and adding the binned column as the first column.\n",
    "\n",
    "    Parameters:\n",
    "        matrix (pd.DataFrame): The input matrix.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The transformed matrix.\n",
    "    \"\"\"\n",
    "    # Extract the first column (dependent variable)\n",
    "    firstcolumn = df.iloc[:, 0].astype('float32')\n",
    "    \n",
    "    # Bin the first column\n",
    "    binned_column = pd.cut(firstcolumn, bins=bins, labels=labels)\n",
    "    \n",
    "    # Add the binned column as the first column\n",
    "    df.insert(loc=0, column='tgt_bin', value=binned_column.iloc[0:].values)\n",
    "    \n",
    "    # Drop columns 3 the first first column\n",
    "    #df = df.drop(columns=df.columns[[3]])\n",
    "\n",
    "    # Return the final matrix\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Prep s4 data for modeling\n",
    "# Example matrix (replace this with your actual matrix)\n",
    "df = pd.DataFrame(s4_data).iloc[1:,] # Convert to DataFrame and drop the first row for binning\n",
    "print(f\"All records at start {df.shape}\")\n",
    "##Only keep records w rain\n",
    "#df = df[df.iloc[:,0]>0]\n",
    "#print(df.shape)\n",
    "\n",
    "#Drop rows where there has been no rain in total area for past 48 hours\n",
    "ndays_check_for_rain = ndays_col\n",
    "range_of_data = ndays_check_for_rain*ndays_col*(24) + ndays_col\n",
    "vc_num = [x for x in range(5,range_of_data,3)]\n",
    "\n",
    "nm1 = 'sum_avg'\n",
    "pds1 = df.iloc[:,vc_num].sum(axis=1,skipna=True)\n",
    "df_area_non_zero = df[pds1 > 0]\n",
    "print(f\"Records with some rain in last {ndays_check_for_rain} days {df_area_non_zero.shape}\")\n",
    "\n",
    "#Separate into dataframes with and withot rain in past n days\n",
    "df_area_non_zero_yrain = df_area_non_zero[df_area_non_zero.iloc[:,0]>0]\n",
    "df_area_non_zero_nrain = df_area_non_zero[df_area_non_zero.iloc[:,0]==0]\n",
    "\n",
    "#sample non-rain to help balance outcomes if needed\n",
    "df_sample_nrain = df_area_non_zero_nrain  #df_area_non_zero_nrain.sample(n=len(df_area_non_zero_yrain))\n",
    "df_area_non_zero_ynrain = pd.concat((df_area_non_zero_yrain,df_sample_nrain),axis=0)\n",
    "\n",
    "#Choose the df for analysis\n",
    "dfs = df_area_non_zero_ynrain\n",
    "print(f\"Full rain and no rain {dfs.shape}\")\n",
    "\n",
    "del df, df_area_non_zero_yrain, df_area_non_zero_nrain, df_area_non_zero_ynrain\n",
    "  \n",
    "# Drop rows where the first column has missing values\n",
    "# df = df.dropna(subset=[0])\n",
    "condition = np.isfinite(dfs.iloc[:,0])\n",
    "df_subset = pd.DataFrame(dfs[condition])\n",
    "del dfs\n",
    "print(df_subset.shape)\n",
    "\n",
    "\n",
    "bins = [-float('inf'),0.1,0.5,1,2,3,4,5,float('inf')]\n",
    "labels = [0,0.1, 0.5,1,2,3,4,5]\n",
    "print(bins, labels)\n",
    "\n",
    "df_transformed = transform_matrix_precip(df_subset, bins, labels)\n",
    "\n",
    "df_transformed.drop(columns=df_transformed.columns[1],inplace=True)\n",
    "df_transformed.shape\n",
    "\n",
    "df_transformed = df_transformed.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(\"Analysis Set:\", df_transformed.shape)\n",
    "\n",
    "print(df_transformed['tgt_bin'].value_counts(dropna=False).sort_index())\n",
    "\n",
    "df_transformed\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#df_transformedn = df_transformed\\ntrain_data, val_data, test_data = split_time_series_data(df_transformed)\\nprint(\"Training Set:\", train_data.shape)\\nprint(train_data[\\'tgt_bin\\'].value_counts(dropna=False).sort_index())\\nprint(\"Validation Set:\", val_data.shape)\\nprint(val_data[\\'tgt_bin\\'].value_counts(dropna=False).sort_index())\\nprint(\"Test Set:\", test_data.shape)\\nprint(test_data[\\'tgt_bin\\'].value_counts(dropna=False).sort_index())\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_time_series_data(df, train_ratio=0.6, val_ratio=0.2, test_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Splits a time series dataset into training, validation, and test sets.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input time series dataset, ordered in descending dates.\n",
    "        train_ratio (float): The proportion of data to use for training.\n",
    "        val_ratio (float): The proportion of data to use for validation.\n",
    "        test_ratio (float): The proportion of data to use for testing.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing three DataFrames (train, validation, test).\n",
    "    \"\"\"\n",
    "    assert train_ratio + val_ratio + test_ratio == 1.0, \"Ratios must sum to 1.0\"\n",
    "\n",
    "    # Calculate split indices\n",
    "    n = len(df)\n",
    "    test_end = int(n * test_ratio)    \n",
    "    val_end = test_end + int(n * val_ratio)\n",
    "    \n",
    "\n",
    "    # Split the data\n",
    "    test_data = df.iloc[:test_end].sort_index(ascending=False)\n",
    "    val_data = df.iloc[test_end:val_end].sort_index(ascending=False)\n",
    "    train_data = df.iloc[val_end:].sort_index(ascending=False)\n",
    "\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "'''\n",
    "#df_transformedn = df_transformed\n",
    "train_data, val_data, test_data = split_time_series_data(df_transformed)\n",
    "print(\"Training Set:\", train_data.shape)\n",
    "print(train_data['tgt_bin'].value_counts(dropna=False).sort_index())\n",
    "print(\"Validation Set:\", val_data.shape)\n",
    "print(val_data['tgt_bin'].value_counts(dropna=False).sort_index())\n",
    "print(\"Test Set:\", test_data.shape)\n",
    "print(test_data['tgt_bin'].value_counts(dropna=False).sort_index())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the station ID and output directory\n",
    "# Export datasets to Parquet and CSV\n",
    "\n",
    "train_data.to_parquet(f\"{ipd04}{stid_target}_train.parquet\", index=False)\n",
    "val_data.to_parquet(f\"{ipd04}{stid_target}_validation.parquet\", index=False)\n",
    "test_data.to_parquet(f\"{ipd04}{stid_target}_test.parquet\", index=False)\n",
    "\n",
    "# code for saving to csv for testing and checking\n",
    "train_data.to_csv(f\"{ipd04}{stid_target}_train.csv\", index=False)\n",
    "# val_data.to_csv(f\"{ipd04}{stid_target}_validation.csv\", index=False)\n",
    "# test_data.to_csv(f\"{ipd04}{stid_target}_test.csv\", index=False)\n",
    "\n",
    "print(\"Datasets exported successfully.\")\n",
    "\n",
    "#python -m s4model --modelname 72406093721 --trainset C:\\\\Users\\\\jhugh\\\\Documents\\\\HT\\\\NCEI_data\\\\metrics_csv\\\\72406093721_train.parquet --valset C:\\\\Users\\\\jhugh\\\\Documents\\\\HT\\\\NCEI_data\\\\metrics_csv\\\\72406093721_validation.parquet --testset C:\\\\Users\\\\jhugh\\\\Documents\\\\HT\\\\NCEI_data\\\\metrics_csv\\\\72406093721_test.parquet --tabulardata --dependent_variable 0 --epochs 30\n",
    "#python -m s4model --modelname 72406093721 --trainset C:\\\\Users\\\\jhugh\\\\Documents\\\\HT\\\\NCEI_data\\\\metrics_csv\\\\72406093721_train.parquet --valset C:\\\\Users\\\\jhugh\\\\Documents\\\\HT\\\\NCEI_data\\\\metrics_csv\\\\72406093721_validation.parquet --testset C:\\\\Users\\\\jhugh\\\\Documents\\\\HT\\\\NCEI_data\\\\metrics_csv\\\\72406093721_test.parquet --tabulardata --dependent_variable 0 --epochs 30\n",
    "\n",
    "\n",
    "# python -m charts --df ../results/72508014740_Test_results_20250424_104121PM.csv --actual 0 --predicted Predicted \n",
    "# python -m charts --df ../results/72508014740_Test_results_20250427_100132PM.csv --actual 0 --predicted Predicted \n",
    "# python -m charts --df ../results/72508014740_Test_results_20250428_091259PM.csv --actual 0 --predicted Predicted \n",
    "# python -m charts --df ../results/72508014740_Test_results_20250428_094033PM.csv --actual 0 --predicted Predicted \n",
    "# python -m charts --df ../results/72508014740_Test_results_20250429_091538PM.csv --actual 0 --predicted Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to run at cmd line\n",
    "#python -m s4model --modelname 72406093721 --trainset C:\\\\Users\\\\jhugh\\\\Documents\\\\HT\\\\NCEI_data\\\\metrics_csv\\\\72406093721_train.parquet --valset C:\\\\Users\\\\jhugh\\\\Documents\\\\HT\\\\NCEI_data\\\\metrics_csv\\\\72406093721_validation.parquet --testset C:\\\\Users\\\\jhugh\\\\Documents\\\\HT\\\\NCEI_data\\\\metrics_csv\\\\72406093721_test.parquet --tabulardata --dependent_variable 0 --epochs 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DAY SUMMARY control\n",
    "def stid_loop(tgt_stid,part):\n",
    "\n",
    "    #Select the target station for which predictions will be made\n",
    "    #tgt_stid =  instid #\"72502014734\" #instid    # \"72502014734\"  large file \"74788012810\"\n",
    "    save_files = 1   #1 means save them and 0 means do not save them\n",
    "    run_files = 1    #1 means do it and 0 means do not do it\n",
    "    print(tgt_stid)\n",
    "    #Nearby stations within 100km\n",
    "    dt_trg_set2 = ipd02 + \"..\\\\Station_Pairs_LE_100km_Info.csv\"\n",
    "    dt_analysis_set2 = pd.read_csv(dt_trg_set2)\n",
    "\n",
    "    dt_analysis_set_keys = fn_get_nearby_stations(tgt_stid,dt_analysis_set2,ipd03)\n",
    "    nstations_in_100km = len(dt_analysis_set_keys) #number of stations within 100 km\n",
    "    num_st_keep = 20   #num of stations to keep for analysis\n",
    "    nstations = min(nstations_in_100km,num_st_keep)\n",
    "    \n",
    "    #dt_analysis_set_keys\n",
    "\n",
    "    #Specify parameters governing the creation of data matrix for analysis\n",
    "    #All the available stations which have all three metrics needed for model\n",
    "    #vc_stid = dt_analysis_set_keys[['st_id']].drop_duplicates()\n",
    "\n",
    "    #Organize the data based on the nature of the data so they all conform to the same size matrices\n",
    "    #The metrics included are\n",
    "    #  AT - air temperature in Celcius\n",
    "    #  RH - relative humidity in Percent\n",
    "    #  PR - precipitation in MM\n",
    "\n",
    "    #Put them all in appropriate matrices and create list of metrics\n",
    "    #Data files are of two types\n",
    "    #    -  24 hour * 365 days * n years  (AT, PR)\n",
    "    #    -  365 days * n years (RH)\n",
    "\n",
    "    #Parameters governing data matrix\n",
    "    stid_target = tgt_stid\n",
    "    stid_keys = dt_analysis_set_keys\n",
    "\n",
    "    ipd = ipd02\n",
    "    nhours = 24\n",
    "    ndays = 365\n",
    "    nmonths_row = 180 #240  #total months on rows of data\n",
    "    nmonths_col = 2 #governs the number of months predicting that are needed\n",
    "    ndays_col = 3  #governs the number of days predicting that are needed\n",
    "    nmetrics = 5  #number of metrics in the data file\n",
    "    tgt_metric =  \"prec\" #\"prec\" \"temp\"    the metric to be modeled\n",
    "    tgt_mod = \"prec_ex01\"  #specifies the metric specific approach for creating data set\n",
    "\n",
    "    #2b. DAY SUMMARY ONE STATION Construct a matrix from most recent to most distant data from the list data by \n",
    "    nstations = 1\n",
    "    ndays_to_target = 3\n",
    "    ndays_col = 30\n",
    "    nmetrics = 6\n",
    "    non_metrics = 1\n",
    "\n",
    "    #Part 1\n",
    "    if part == 1:\n",
    "        #Get data for target station\n",
    "        lst_data = fn_select_data_vectors_pr07(stid_keys,nstations,nhours,nmonths_row,nmonths_col)\n",
    "        fn = f\"lst data done\"\n",
    "        print(fn)\n",
    "        \n",
    "        #Create matrix of data    \n",
    "        mtx_data = fn_create_data_matrix_DAY_SUMMARY(lst_data,tgt_metric,nstations,nmetrics,non_metrics,nmonths_col,ndays_col,ndays_to_target)\n",
    "        fn = f\"mtx data done - DAY SUMMARY ONE STATION\"\n",
    "        print(fn)\n",
    "        print(mtx_data.shape)\n",
    "        \n",
    "        #Save the mtx_data to a folder\n",
    "        print(ipd04)        \n",
    "        rtn_mtx_pqt = pd.DataFrame(mtx_data)\n",
    "        print(rtn_mtx_pqt.shape)\n",
    "        fn = f\"{ipd04}{tgt_metric}_mtx_DAY_SUMMARY_{stid_target}_stations_{nstations}_RowMn_{nmonths_row}_ColDy_{ndays_col}.parquet\"\n",
    "        print(fn)\n",
    "        rtn_mtx_pqt.to_parquet(fn, index=False)\n",
    "    \n",
    "    #End part 1        \n",
    "\n",
    "    #Part 2\n",
    "    if part == 2:\n",
    "        #Get the mtx_data from a folder\n",
    "        #This lets us start at Step 3 for iterative runs\n",
    "        fn = f\"{ipd04}{tgt_metric}_mtx_DAY_SUMMARY_{stid_target}_stations_{nstations}_RowMn_{nmonths_row}_ColDy_{ndays_col}.parquet\"\n",
    "        rtn_mtx_data_all = pd.read_parquet(fn)\n",
    "        rtn_mtx_data = rtn_mtx_data_all.head(30000)\n",
    "        print(rtn_mtx_data.shape)\n",
    "        \n",
    "        mtx_data = rtn_mtx_data.to_numpy()\n",
    "        del rtn_mtx_data_all\n",
    "\n",
    "        #DAY SUMMARY Create a target variable, select feature variables, create data frame for input into s4 analysis\n",
    "        s4_data = fn_create_DAY_SUMMARY_tgt_matrix_pr07(mtx_data,\"prec\",\"prec_ex02\",1,nmetrics,ndays_col,ndays_to_target)\n",
    "        fn = f\"s4 matrix with target data done\"\n",
    "        print(ipd04)\n",
    "        print(fn)\n",
    "        \n",
    "        rtn_s4_data_pqt = pd.DataFrame(s4_data)\n",
    "        print(rtn_s4_data_pqt.shape)\n",
    "        fn = f\"{ipd04}{tgt_metric}_s4data_DAY_SUMMARY_{stid_target}_stations_{nstations}_RowMn_{nmonths_row}_ColDy_{ndays_col}.parquet\"\n",
    "\n",
    "        print(fn)\n",
    "        rtn_s4_data_pqt.to_parquet(fn, index=False)\n",
    "\n",
    "    \n",
    "    if part == 3:\n",
    "        #This lets us start at Step 4 for iterative runs DAY SUMMARY\n",
    "        fn = f\"{ipd04}{tgt_metric}_s4data_DAY_SUMMARY_{stid_target}_stations_{nstations}_RowMn_{nmonths_row}_ColDy_{ndays_col}.parquet\"\n",
    "        print(fn)\n",
    "\n",
    "        # Read the Parquet file into a Pandas DataFrame\n",
    "        s4_data = pd.read_parquet(fn)\n",
    "        print(s4_data.shape)\n",
    "        \n",
    "        # Prep s4 data for modeling DAY SUMMARY\n",
    "        # Example matrix (replace this with your actual matrix)\n",
    "        df = pd.DataFrame(s4_data).iloc[1:,] # Convert to DataFrame and drop the first row for binning\n",
    "        print(f\"All records at start {df.shape}\")\n",
    "    \n",
    "        #Drop rows where there has been no rain in total area for past 48 hours\n",
    "        #Choose the df for analysis\n",
    "        dfs = df\n",
    "        #print(f\"Full rain and no rain {dfs.shape}\")\n",
    "\n",
    "        # Drop rows where the first column has missing values\n",
    "        # df = df.dropna(subset=[0])\n",
    "        condition = np.isfinite(dfs.iloc[:,0])\n",
    "        df_subset = pd.DataFrame(dfs[condition])\n",
    "        del dfs\n",
    "        print(f\"First missing values dropped {df_subset.shape}\")\n",
    "\n",
    "\n",
    "        bins = [-float('inf'),0.1,0.5,1,2,3,4,5,float('inf')]\n",
    "        labels = [0,0.1, 0.5,1,2,3,4,5]\n",
    "        print(bins, labels)\n",
    "\n",
    "        df_transformed = transform_matrix_precip(df_subset, bins, labels)\n",
    "\n",
    "        df_transformed.drop(columns=df_transformed.columns[1],inplace=True)\n",
    "\n",
    "        df_transformed = df_transformed.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        print(\"Analysis Set:\", df_transformed.shape)\n",
    "        print(df_transformed['tgt_bin'].value_counts(dropna=False).sort_index())\n",
    "\n",
    "        #Convert day and mon from char to numeric\n",
    "        col_name_mon = 1\n",
    "        col_name_hour = 2\n",
    "        column_name_mn = df_transformed.columns[col_name_mon]\n",
    "        column_name_hr = df_transformed.columns[col_name_hour]\n",
    "        df_transformed[column_name_mn] = pd.to_numeric(df_transformed[column_name_mn], errors='coerce') \n",
    "        df_transformed[column_name_hr] = pd.to_numeric(df_transformed[column_name_hr], errors='coerce') \n",
    "        \n",
    "        df_transformed\n",
    "        \n",
    "        \n",
    "        #df_transformedn = df_transformed\n",
    "        train_data, val_data, test_data = split_time_series_data(df_transformed)\n",
    "        print(\"Training Set:\", train_data.shape)\n",
    "        print(train_data['tgt_bin'].value_counts(dropna=False).sort_index())\n",
    "        print(\"Validation Set:\", val_data.shape)\n",
    "        print(val_data['tgt_bin'].value_counts(dropna=False).sort_index())\n",
    "        print(\"Test Set:\", test_data.shape)\n",
    "        print(test_data['tgt_bin'].value_counts(dropna=False).sort_index())\n",
    "\n",
    "        # Define the station ID and output directory\n",
    "        # Export datasets to Parquet and CSV\n",
    "\n",
    "        train_data.to_parquet(f\"{ipd04}{stid_target}_DAYSUM_train.parquet\", index=False)\n",
    "        val_data.to_parquet(f\"{ipd04}{stid_target}_DAYSUM_validation.parquet\", index=False)\n",
    "        test_data.to_parquet(f\"{ipd04}{stid_target}_DAYSUM_test.parquet\", index=False)\n",
    "\n",
    "        # code for saving to csv for testing and checking\n",
    "        #train_data.to_csv(f\"{ipd04}{stid_target}_DAYSUM_train.csv\", index=False)\n",
    "        # val_data.to_csv(f\"{ipd04}{stid_target}_validation.csv\", index=False)\n",
    "        # test_data.to_csv(f\"{ipd04}{stid_target}_test.csv\", index=False)\n",
    "        print(\"Datasets exported successfully.\")\n",
    "\n",
    "        #Code to run at cmd line\n",
    "        #python -m s4model --modelname 72406093721 --trainset C:\\\\Users\\\\jhugh\\\\Documents\\\\HT\\\\NCEI_data\\\\metrics_csv\\\\72406093721_train.parquet --valset C:\\\\Users\\\\jhugh\\\\Documents\\\\HT\\\\NCEI_data\\\\metrics_csv\\\\72406093721_validation.parquet --testset C:\\\\Users\\\\jhugh\\\\Documents\\\\HT\\\\NCEI_data\\\\metrics_csv\\\\72406093721_test.parquet --tabulardata --dependent_variable 0 --epochs 30\n",
    "        \n",
    "        \n",
    "    return test_data #mtx_data #tgt_stid #s4_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72218003820\n",
      "\\\\CXA01\\Users\\jhugh\\Documents\\Py_S4\\NCEI_parquet_files\\prec_s4data_DAY_SUMMARY_72218003820_stations_1_RowMn_180_ColDy_30.parquet\n",
      "(128807, 4682)\n",
      "All records at start (128806, 4682)\n",
      "First missing values dropped (128806, 4682)\n",
      "[-inf, 0.1, 0.5, 1, 2, 3, 4, 5, inf] [0, 0.1, 0.5, 1, 2, 3, 4, 5]\n",
      "Analysis Set: (128806, 4682)\n",
      "tgt_bin\n",
      "0.0    88890\n",
      "0.1     6010\n",
      "0.5     3077\n",
      "1.0     3793\n",
      "2.0     2278\n",
      "3.0     1730\n",
      "4.0     1470\n",
      "5.0    21558\n",
      "Name: count, dtype: int64\n",
      "Training Set: (77284, 4682)\n",
      "tgt_bin\n",
      "0.0    53502\n",
      "0.1     3559\n",
      "0.5     1830\n",
      "1.0     2269\n",
      "2.0     1325\n",
      "3.0     1032\n",
      "4.0      913\n",
      "5.0    12854\n",
      "Name: count, dtype: int64\n",
      "Validation Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    17707\n",
      "0.1     1202\n",
      "0.5      601\n",
      "1.0      767\n",
      "2.0      451\n",
      "3.0      375\n",
      "4.0      275\n",
      "5.0     4383\n",
      "Name: count, dtype: int64\n",
      "Test Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    17681\n",
      "0.1     1249\n",
      "0.5      646\n",
      "1.0      757\n",
      "2.0      502\n",
      "3.0      323\n",
      "4.0      282\n",
      "5.0     4321\n",
      "Name: count, dtype: int64\n",
      "Datasets exported successfully.\n",
      "Done with       tgt_bin   0   1        75         76       77         78        79  \\\n",
      "25760     0.0  12   9  0.000000   5.027344   99.625  46.750000  79.50000   \n",
      "25759     0.0  10  19  0.000000  15.093750   91.750  28.046875  56.09375   \n",
      "25758     0.0   9  21  0.000000        NaN      NaN        NaN       NaN   \n",
      "25757     0.0   1  14  0.000000  10.703125  100.000  66.750000  85.75000   \n",
      "25756     0.0   3  18  0.000000  12.218750   91.250  41.250000  64.75000   \n",
      "...       ...  ..  ..       ...        ...      ...        ...       ...   \n",
      "4         0.0   4  22  0.000000  14.570312   84.750  34.593750  55.59375   \n",
      "3         0.0   7   8  0.237549  26.921875   95.500  54.843750  78.68750   \n",
      "2         0.0  11   5  0.000000  11.539062  100.000  76.437500  92.06250   \n",
      "1         0.0   3   2  0.000000  13.476562   93.000  18.078125  56.00000   \n",
      "0         5.0   4  19  0.000000  14.257812   81.750  14.164062  39.65625   \n",
      "\n",
      "             80        81  ...       4744      4745       4746      4747  \\\n",
      "25760  0.000000  0.000000  ...  16.109375   98.3750  69.125000  90.56250   \n",
      "25759  0.000000  0.000000  ...  25.187500  100.0000  38.000000  73.25000   \n",
      "25758  0.000000  0.000000  ...  27.156250  100.0000  40.968750  73.06250   \n",
      "25757  0.000000  0.000000  ...  15.648438   96.6875  52.343750  79.68750   \n",
      "25756  0.000000  0.000000  ...  -4.082031   95.3125  57.156250  76.18750   \n",
      "...         ...       ...  ...        ...       ...        ...       ...   \n",
      "4      0.000000  0.000000  ...   8.375000  100.0000  74.000000  87.00000   \n",
      "3      5.699219  0.237549  ...  26.906250   94.0625  43.906250  75.25000   \n",
      "2      0.000000  0.000000  ...  21.578125  100.0000  45.906250  80.75000   \n",
      "1      0.000000  0.000000  ...  11.851562   86.8125  22.171875  54.84375   \n",
      "0      0.000000  0.000000  ...  17.468750   93.3750  31.875000  62.75000   \n",
      "\n",
      "           4748      4749       4750      4751      4752      4753  \n",
      "25760  7.199219  0.300049  16.406250   98.2500  69.75000  90.56250  \n",
      "25759  0.000000  0.000000  25.140625  100.0000  38.00000  73.31250  \n",
      "25758  0.000000  0.000000  27.343750  100.0000  40.90625  73.06250  \n",
      "25757  2.099609  0.087524  15.414062   96.6250  51.75000  79.50000  \n",
      "25756  0.000000  0.000000  -4.277344   95.1875  55.46875  75.18750  \n",
      "...         ...       ...        ...       ...       ...       ...  \n",
      "4      0.000000  0.000000   8.148438   99.5625  72.68750  86.43750  \n",
      "3      1.299805  0.054169  27.031250   94.3750  44.12500  75.62500  \n",
      "2      0.000000  0.000000  21.359375  100.0000  45.50000  80.50000  \n",
      "1      0.000000  0.000000  11.523438   86.3750  22.37500  54.87500  \n",
      "0      0.000000  0.000000  17.421875   93.5000  31.50000  62.65625  \n",
      "\n",
      "[25761 rows x 4682 columns]\n",
      "72223013894\n",
      "\\\\CXA01\\Users\\jhugh\\Documents\\Py_S4\\NCEI_parquet_files\\prec_s4data_DAY_SUMMARY_72223013894_stations_1_RowMn_180_ColDy_30.parquet\n",
      "(128807, 4682)\n",
      "All records at start (128806, 4682)\n",
      "First missing values dropped (128806, 4682)\n",
      "[-inf, 0.1, 0.5, 1, 2, 3, 4, 5, inf] [0, 0.1, 0.5, 1, 2, 3, 4, 5]\n",
      "Analysis Set: (128806, 4682)\n",
      "tgt_bin\n",
      "0.0    84914\n",
      "0.1     4743\n",
      "0.5     3019\n",
      "1.0     3799\n",
      "2.0     2586\n",
      "3.0     1811\n",
      "4.0     1365\n",
      "5.0    26569\n",
      "Name: count, dtype: int64\n",
      "Training Set: (77284, 4682)\n",
      "tgt_bin\n",
      "0.0    50956\n",
      "0.1     2821\n",
      "0.5     1821\n",
      "1.0     2294\n",
      "2.0     1547\n",
      "3.0     1102\n",
      "4.0      772\n",
      "5.0    15971\n",
      "Name: count, dtype: int64\n",
      "Validation Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    16879\n",
      "0.1      982\n",
      "0.5      633\n",
      "1.0      759\n",
      "2.0      542\n",
      "3.0      345\n",
      "4.0      292\n",
      "5.0     5329\n",
      "Name: count, dtype: int64\n",
      "Test Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    17079\n",
      "0.1      940\n",
      "0.5      565\n",
      "1.0      746\n",
      "2.0      497\n",
      "3.0      364\n",
      "4.0      301\n",
      "5.0     5269\n",
      "Name: count, dtype: int64\n",
      "Datasets exported successfully.\n",
      "Done with       tgt_bin   0   1        75         76        77         78       79  \\\n",
      "25760     0.0  12  21  2.400391  17.859375  100.0000  74.500000  91.1250   \n",
      "25759     0.0   4  12  0.000000  15.898438   89.0000  24.000000  57.0000   \n",
      "25758     5.0  12  22  5.796875  17.500000   91.8125  60.156250  77.4375   \n",
      "25757     0.0  10   9  0.000000  21.296875   79.2500  35.625000  53.8750   \n",
      "25756     5.0   7  18  0.000000  27.656250   91.0000  60.000000  77.0000   \n",
      "...       ...  ..  ..       ...        ...       ...        ...      ...   \n",
      "4         0.0  11   9  0.000000  10.742188   77.7500  38.750000  58.3750   \n",
      "3         0.0   5   4  0.000000  19.453125   91.0000  30.671875  58.0000   \n",
      "2         0.0   3  13  0.000000  20.750000  100.0000  44.843750  80.2500   \n",
      "1         0.0   8  22  0.104187  28.078125   98.2500  65.937500  86.9375   \n",
      "0         0.0   5  22  0.000000  26.953125   90.0000  44.156250  69.7500   \n",
      "\n",
      "              80        81  ...       4744     4745       4746     4747  \\\n",
      "25760   57.59375  2.400391  ...  13.898438   99.875  22.421875  69.0625   \n",
      "25759    0.00000  0.000000  ...  11.742188   94.250  42.250000  63.7500   \n",
      "25758  139.12500  5.796875  ...  15.367188  100.000  94.000000  99.0000   \n",
      "25757    0.00000  0.000000  ...  25.531250   98.625  66.937500  87.3125   \n",
      "25756    0.00000  0.000000  ...  27.218750   90.000  63.656250  81.5000   \n",
      "...          ...       ...  ...        ...      ...        ...      ...   \n",
      "4        0.00000  0.000000  ...  23.796875   88.625  57.406250  74.7500   \n",
      "3        0.00000  0.000000  ...  22.218750   99.250  52.500000  79.7500   \n",
      "2        0.00000  0.000000  ...  16.328125   96.375  43.875000  71.8750   \n",
      "1        2.50000  0.104187  ...  23.078125   97.000  54.000000  81.0000   \n",
      "0        0.00000  0.000000  ...  20.078125   91.000  22.000000  46.0000   \n",
      "\n",
      "            4748      4749       4750      4751       4752      4753  \n",
      "25760   0.000000  0.000000  13.859375   99.7500  22.828125  69.18750  \n",
      "25759   0.000000  0.000000  11.609375   94.3750  44.375000  65.12500  \n",
      "25758   0.000000  0.000000  15.414062  100.0000  93.062500  98.56250  \n",
      "25757   0.000000  0.000000  25.593750   98.7500  67.437500  87.68750  \n",
      "25756   0.000000  0.000000  27.046875   90.0000  62.843750  81.37500  \n",
      "...          ...       ...        ...       ...        ...       ...  \n",
      "4       0.000000  0.000000  23.703125   88.7500  56.843750  74.50000  \n",
      "3      16.906250  0.704102  21.968750   99.3750  53.750000  80.43750  \n",
      "2       3.300781  0.137451  16.281250   96.4375  43.093750  71.75000  \n",
      "1      90.187500  3.757812  23.140625   97.1250  54.218750  81.00000  \n",
      "0       0.000000  0.000000  20.062500   91.0625  23.500000  47.15625  \n",
      "\n",
      "[25761 rows x 4682 columns]\n",
      "72241012917\n",
      "\\\\CXA01\\Users\\jhugh\\Documents\\Py_S4\\NCEI_parquet_files\\prec_s4data_DAY_SUMMARY_72241012917_stations_1_RowMn_180_ColDy_30.parquet\n",
      "(128807, 4682)\n",
      "All records at start (128806, 4682)\n",
      "First missing values dropped (128806, 4682)\n",
      "[-inf, 0.1, 0.5, 1, 2, 3, 4, 5, inf] [0, 0.1, 0.5, 1, 2, 3, 4, 5]\n",
      "Analysis Set: (128806, 4682)\n",
      "tgt_bin\n",
      "0.0    89059\n",
      "0.1     6241\n",
      "0.5     2992\n",
      "1.0     3428\n",
      "2.0     1995\n",
      "3.0     1356\n",
      "4.0     1170\n",
      "5.0    22565\n",
      "Name: count, dtype: int64\n",
      "Training Set: (77284, 4682)\n",
      "tgt_bin\n",
      "0.0    53374\n",
      "0.1     3779\n",
      "0.5     1798\n",
      "1.0     2095\n",
      "2.0     1193\n",
      "3.0      819\n",
      "4.0      699\n",
      "5.0    13527\n",
      "Name: count, dtype: int64\n",
      "Validation Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    17816\n",
      "0.1     1261\n",
      "0.5      611\n",
      "1.0      679\n",
      "2.0      408\n",
      "3.0      258\n",
      "4.0      235\n",
      "5.0     4493\n",
      "Name: count, dtype: int64\n",
      "Test Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    17869\n",
      "0.1     1201\n",
      "0.5      583\n",
      "1.0      654\n",
      "2.0      394\n",
      "3.0      279\n",
      "4.0      236\n",
      "5.0     4545\n",
      "Name: count, dtype: int64\n",
      "Datasets exported successfully.\n",
      "Done with       tgt_bin   0   1        75         76        77         78        79  \\\n",
      "25760     0.0   9  21  0.304199  25.156250   96.2500  52.500000  75.62500   \n",
      "25759     5.0   5  11  1.029297  23.609375   91.0000  57.406250  78.12500   \n",
      "25758     0.0  11  17  0.000000  16.140625  100.0000  69.687500  90.31250   \n",
      "25757     0.0  12  16  0.000000  10.679688   95.6875  40.500000  63.34375   \n",
      "25756     0.0  10  19  0.000000  17.640625   86.3125  22.421875  52.46875   \n",
      "...       ...  ..  ..       ...        ...       ...        ...       ...   \n",
      "4         0.0   7  14  0.000000  29.687500   97.0000  47.593750  76.75000   \n",
      "3         0.0   2  17  0.000000  17.671875   93.8125  84.062500  89.18750   \n",
      "2         0.0   2  11  0.000000  12.171875   99.8125  26.000000  61.53125   \n",
      "1         0.0   6  13  0.000000  29.609375   90.1875  46.000000  67.12500   \n",
      "0         5.0   8   6  0.570801  29.703125   94.0000  49.250000  75.50000   \n",
      "\n",
      "              80        81  ...       4744      4745       4746      4747  \\\n",
      "25760   7.300781  0.304199  ...  28.281250   97.0000  61.000000  81.25000   \n",
      "25759  24.703125  1.029297  ...  20.421875   98.6250  41.031250  72.12500   \n",
      "25758   0.000000  0.000000  ...  25.796875  100.0000  67.687500  84.00000   \n",
      "25757   0.000000  0.000000  ...  18.265625  100.0000  60.750000  86.50000   \n",
      "25756   0.000000  0.000000  ...  27.609375   92.6250  53.375000  76.12500   \n",
      "...          ...       ...  ...        ...       ...        ...       ...   \n",
      "4       0.000000  0.000000  ...  28.578125   96.3125  57.343750  76.31250   \n",
      "3       0.000000  0.000000  ...  10.132812   87.1875  18.796875  57.71875   \n",
      "2       0.000000  0.000000  ...   7.523438   86.1875  40.343750  60.78125   \n",
      "1       0.000000  0.000000  ...  19.343750   94.5000  33.250000  56.37500   \n",
      "0       2.300781  0.095825  ...  28.437500   94.0000  54.343750  76.00000   \n",
      "\n",
      "         4748      4749       4750      4751      4752     4753  \n",
      "25760    0.00  0.000000  28.250000   97.0000  61.00000  81.5000  \n",
      "25759    0.00  0.000000  20.312500   98.5000  41.50000  72.5000  \n",
      "25758  145.75  6.070312  25.843750  100.0000  67.25000  84.0000  \n",
      "25757    0.00  0.000000  18.156250  100.0000  60.53125  86.4375  \n",
      "25756    0.00  0.000000  27.656250   92.5000  53.50000  76.1875  \n",
      "...       ...       ...        ...       ...       ...      ...  \n",
      "4        2.00  0.083313  28.468750   96.3750  57.00000  76.1250  \n",
      "3        0.00  0.000000  10.031250   87.0000  18.75000  57.2500  \n",
      "2        0.00  0.000000   7.175781   87.0000  40.00000  60.5000  \n",
      "1        0.00  0.000000  19.390625   94.6875  33.15625  56.7500  \n",
      "0        0.00  0.000000  28.312500   94.0000  54.03125  75.8750  \n",
      "\n",
      "[25761 rows x 4682 columns]\n",
      "72250012919\n",
      "\\\\CXA01\\Users\\jhugh\\Documents\\Py_S4\\NCEI_parquet_files\\prec_s4data_DAY_SUMMARY_72250012919_stations_1_RowMn_180_ColDy_30.parquet\n",
      "(128807, 4682)\n",
      "All records at start (128806, 4682)\n",
      "First missing values dropped (128806, 4682)\n",
      "[-inf, 0.1, 0.5, 1, 2, 3, 4, 5, inf] [0, 0.1, 0.5, 1, 2, 3, 4, 5]\n",
      "Analysis Set: (128806, 4682)\n",
      "tgt_bin\n",
      "0.0    100877\n",
      "0.1      4922\n",
      "0.5      2915\n",
      "1.0      3320\n",
      "2.0      2001\n",
      "3.0      1575\n",
      "4.0       908\n",
      "5.0     12288\n",
      "Name: count, dtype: int64\n",
      "Training Set: (77284, 4682)\n",
      "tgt_bin\n",
      "0.0    60511\n",
      "0.1     2972\n",
      "0.5     1722\n",
      "1.0     2005\n",
      "2.0     1222\n",
      "3.0      951\n",
      "4.0      549\n",
      "5.0     7352\n",
      "Name: count, dtype: int64\n",
      "Validation Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    20119\n",
      "0.1     1025\n",
      "0.5      595\n",
      "1.0      657\n",
      "2.0      386\n",
      "3.0      294\n",
      "4.0      195\n",
      "5.0     2490\n",
      "Name: count, dtype: int64\n",
      "Test Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    20247\n",
      "0.1      925\n",
      "0.5      598\n",
      "1.0      658\n",
      "2.0      393\n",
      "3.0      330\n",
      "4.0      164\n",
      "5.0     2446\n",
      "Name: count, dtype: int64\n",
      "Datasets exported successfully.\n",
      "Done with       tgt_bin  0   1       75         76       77        78       79  \\\n",
      "25760     0.0  4   0  0.00000  24.421875  90.0000  57.00000  75.5000   \n",
      "25759     0.0  5   1  0.00000  26.953125  95.3750  56.84375  80.4375   \n",
      "25758     0.0  3   6  0.00000  25.750000  93.2500  37.25000  79.0000   \n",
      "25757     0.0  6  10  0.00000  27.500000  99.6875  58.50000  79.6875   \n",
      "25756     0.0  1  10  0.00000  18.843750  96.3125  36.90625  69.0625   \n",
      "...       ... ..  ..      ...        ...      ...       ...      ...   \n",
      "4         0.0  8  16  0.00000  29.500000  90.0000  48.50000  72.0000   \n",
      "3         0.5  8  23  0.19165  28.921875  94.0000  43.34375  71.5625   \n",
      "2         0.0  6  11  0.00000  32.187500  89.9375  49.12500  73.0000   \n",
      "1         0.0  9  18  0.00000  29.328125  93.7500  58.00000  76.5000   \n",
      "0         0.0  3  18  0.00000  23.312500  96.2500  64.25000  81.7500   \n",
      "\n",
      "             80       81  ...       4744      4745      4746     4747  \\\n",
      "25760  0.000000  0.00000  ...  26.406250   90.3125  57.65625  78.1875   \n",
      "25759  0.000000  0.00000  ...  23.781250   96.5000  61.12500  80.0000   \n",
      "25758  0.000000  0.00000  ...  23.156250   99.0000  59.65625  85.3125   \n",
      "25757  0.000000  0.00000  ...  19.968750   90.0000  39.00000  56.5000   \n",
      "25756  0.000000  0.00000  ...  24.187500   95.5000  62.00000  81.0000   \n",
      "...         ...      ...  ...        ...       ...       ...      ...   \n",
      "4      0.000000  0.00000  ...  30.625000   90.0000  48.25000  70.2500   \n",
      "3      4.601562  0.19165  ...  29.140625   95.9375  56.12500  76.0000   \n",
      "2      0.000000  0.00000  ...  28.187500   91.0000  65.43750  80.9375   \n",
      "1      0.000000  0.00000  ...  30.046875   90.5000  56.50000  75.5000   \n",
      "0      0.000000  0.00000  ...  13.250000  100.0000  77.68750  96.3125   \n",
      "\n",
      "           4748      4749       4750      4751      4752      4753  \n",
      "25760  0.000000  0.000000  26.406250   90.1875  57.34375  78.06250  \n",
      "25759  0.000000  0.000000  23.796875   96.3125  61.40625  80.00000  \n",
      "25758  0.000000  0.000000  23.125000   99.1250  59.09375  85.18750  \n",
      "25757  0.000000  0.000000  20.093750   90.8125  38.40625  56.03125  \n",
      "25756  0.000000  0.000000  24.265625   95.3750  61.90625  81.06250  \n",
      "...         ...       ...        ...       ...       ...       ...  \n",
      "4      0.000000  0.000000  30.593750   90.0000  48.28125  70.31250  \n",
      "3      0.000000  0.000000  29.125000   96.0000  56.00000  76.00000  \n",
      "2      0.000000  0.000000  28.218750   91.0000  65.50000  81.00000  \n",
      "1      2.599609  0.108337  30.093750   90.6250  56.12500  75.37500  \n",
      "0      1.099609  0.045837  13.445312  100.0000  77.56250  95.93750  \n",
      "\n",
      "[25761 rows x 4682 columns]\n",
      "72251012924\n",
      "\\\\CXA01\\Users\\jhugh\\Documents\\Py_S4\\NCEI_parquet_files\\prec_s4data_DAY_SUMMARY_72251012924_stations_1_RowMn_180_ColDy_30.parquet\n",
      "(128807, 4682)\n",
      "All records at start (128806, 4682)\n",
      "First missing values dropped (128806, 4682)\n",
      "[-inf, 0.1, 0.5, 1, 2, 3, 4, 5, inf] [0, 0.1, 0.5, 1, 2, 3, 4, 5]\n",
      "Analysis Set: (128806, 4682)\n",
      "tgt_bin\n",
      "0.0    101362\n",
      "0.1      5423\n",
      "0.5      2777\n",
      "1.0      3151\n",
      "2.0      1850\n",
      "3.0      1452\n",
      "4.0      1143\n",
      "5.0     11648\n",
      "Name: count, dtype: int64\n",
      "Training Set: (77284, 4682)\n",
      "tgt_bin\n",
      "0.0    60963\n",
      "0.1     3240\n",
      "0.5     1630\n",
      "1.0     1852\n",
      "2.0     1073\n",
      "3.0      899\n",
      "4.0      708\n",
      "5.0     6919\n",
      "Name: count, dtype: int64\n",
      "Validation Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    20151\n",
      "0.1     1109\n",
      "0.5      580\n",
      "1.0      640\n",
      "2.0      405\n",
      "3.0      297\n",
      "4.0      206\n",
      "5.0     2373\n",
      "Name: count, dtype: int64\n",
      "Test Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    20248\n",
      "0.1     1074\n",
      "0.5      567\n",
      "1.0      659\n",
      "2.0      372\n",
      "3.0      256\n",
      "4.0      229\n",
      "5.0     2356\n",
      "Name: count, dtype: int64\n",
      "Datasets exported successfully.\n",
      "Done with       tgt_bin   0   1        75         76       77        78       79  \\\n",
      "25760     0.0   8  21  0.000000  28.343750  92.5000  39.25000  69.7500   \n",
      "25759     0.0   7  16  0.000000  28.937500  97.0000  67.50000  86.1875   \n",
      "25758     0.0   7  18  0.000000  30.546875  89.5000  41.50000  67.5000   \n",
      "25757     0.0   3  10  0.000000  24.937500  99.7500  75.43750  88.6875   \n",
      "25756     0.0   7   2  0.000000  27.984375  97.0000  62.75000  82.6875   \n",
      "...       ...  ..  ..       ...        ...      ...       ...      ...   \n",
      "4         0.5  10  14  0.000000  21.671875  90.0000  51.15625  66.0625   \n",
      "3         2.0   6  15  0.099976  28.093750  88.3750  66.50000  78.5000   \n",
      "2         0.0   1  11  0.000000  15.320312  99.8125  58.34375  87.8750   \n",
      "1         0.0   4   8  0.000000  23.781250  95.8125  35.50000  71.5000   \n",
      "0         0.0  10  20  0.083313  15.062500      NaN       NaN      NaN   \n",
      "\n",
      "             80        81  ...       4744   4745       4746      4747  \\\n",
      "25760  0.000000  0.000000  ...  28.546875  100.0  54.000000  77.00000   \n",
      "25759  0.000000  0.000000  ...  28.906250   97.0  69.000000  83.25000   \n",
      "25758  0.000000  0.000000  ...  26.968750   84.5  57.843750  71.50000   \n",
      "25757  0.000000  0.000000  ...  16.500000   98.0  35.500000  70.50000   \n",
      "25756  0.000000  0.000000  ...  28.828125  100.0  61.000000  81.00000   \n",
      "...         ...       ...  ...        ...    ...        ...       ...   \n",
      "4      0.000000  0.000000  ...  30.046875   99.0  55.000000  78.00000   \n",
      "3      2.400391  0.099976  ...  29.375000   88.0  59.281250  75.68750   \n",
      "2      0.000000  0.000000  ...  18.531250  100.0  64.562500  86.06250   \n",
      "1      0.000000  0.000000  ...  17.656250   86.5  29.921875  49.34375   \n",
      "0      2.000000  0.083313  ...  28.812500   90.5  51.343750  75.81250   \n",
      "\n",
      "            4748      4749       4750      4751      4752     4753  \n",
      "25760   1.000000  0.041656  28.843750  100.0000  54.00000  77.0000  \n",
      "25759   0.000000  0.000000  28.890625   97.0000  69.18750  83.3125  \n",
      "25758  14.398438  0.600098  27.031250   84.3750  57.53125  71.3750  \n",
      "25757   0.000000  0.000000  16.500000   98.1875  36.12500  71.4375  \n",
      "25756   0.000000  0.000000  28.843750  100.0000  61.25000  81.0000  \n",
      "...          ...       ...        ...       ...       ...      ...  \n",
      "4       0.000000  0.000000  30.062500   98.8750  54.87500  77.8750  \n",
      "3       0.000000  0.000000  29.343750   88.0000  59.34375  75.6875  \n",
      "2       0.000000  0.000000  18.390625  100.0000  64.00000  86.0000  \n",
      "1       0.000000  0.000000  17.515625   87.2500  29.12500  48.5000  \n",
      "0       0.000000  0.000000  28.765625   90.2500  51.00000  75.2500  \n",
      "\n",
      "[25761 rows x 4682 columns]\n",
      "72255012912\n",
      "\\\\CXA01\\Users\\jhugh\\Documents\\Py_S4\\NCEI_parquet_files\\prec_s4data_DAY_SUMMARY_72255012912_stations_1_RowMn_180_ColDy_30.parquet\n",
      "(128807, 4682)\n",
      "All records at start (128806, 4682)\n",
      "First missing values dropped (128806, 4682)\n",
      "[-inf, 0.1, 0.5, 1, 2, 3, 4, 5, inf] [0, 0.1, 0.5, 1, 2, 3, 4, 5]\n",
      "Analysis Set: (128806, 4682)\n",
      "tgt_bin\n",
      "0.0    96541\n",
      "0.1     5579\n",
      "0.5     3201\n",
      "1.0     3471\n",
      "2.0     2036\n",
      "3.0     1553\n",
      "4.0     1164\n",
      "5.0    15261\n",
      "Name: count, dtype: int64\n",
      "Training Set: (77284, 4682)\n",
      "tgt_bin\n",
      "0.0    57873\n",
      "0.1     3358\n",
      "0.5     1917\n",
      "1.0     2045\n",
      "2.0     1197\n",
      "3.0      939\n",
      "4.0      711\n",
      "5.0     9244\n",
      "Name: count, dtype: int64\n",
      "Validation Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    19233\n",
      "0.1     1141\n",
      "0.5      655\n",
      "1.0      733\n",
      "2.0      418\n",
      "3.0      321\n",
      "4.0      224\n",
      "5.0     3036\n",
      "Name: count, dtype: int64\n",
      "Test Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    19435\n",
      "0.1     1080\n",
      "0.5      629\n",
      "1.0      693\n",
      "2.0      421\n",
      "3.0      293\n",
      "4.0      229\n",
      "5.0     2981\n",
      "Name: count, dtype: int64\n",
      "Datasets exported successfully.\n",
      "Done with       tgt_bin   0   1        75         76        77        78       79  \\\n",
      "25760     0.0  12   1  0.000000  20.437500  100.0000  51.21875  84.9375   \n",
      "25759     0.0  12  18  0.000000  10.796875   93.7500  53.75000  77.7500   \n",
      "25758     0.0   7   4  0.000000  28.640625   98.0000  75.31250  89.3125   \n",
      "25757     0.0  12  13  0.012497  20.093750   99.5625  63.84375  81.6875   \n",
      "25756     0.0  12  16  0.000000  21.296875       NaN       NaN      NaN   \n",
      "...       ...  ..  ..       ...        ...       ...       ...      ...   \n",
      "4         0.0   1  18  0.000000   7.710938   97.0000  38.75000  70.0000   \n",
      "3         4.0   5   0  0.208374  23.453125   91.5000  54.50000  72.0000   \n",
      "2         0.5  12  17  0.000000  19.406250   96.1875  53.65625  77.4375   \n",
      "1         0.0   3  12  0.000000  21.218750  100.0000  80.00000  94.0000   \n",
      "0         0.0   7   5  0.000000  30.281250   95.8125  46.00000  71.1250   \n",
      "\n",
      "             80        81  ...       4744      4745       4746      4747  \\\n",
      "25760  0.000000  0.000000  ...  22.250000   97.3750  45.125000  76.75000   \n",
      "25759  0.000000  0.000000  ...  13.484375   94.1875  37.843750  60.34375   \n",
      "25758  0.000000  0.000000  ...  26.796875  100.0000  46.000000  75.25000   \n",
      "25757  0.300049  0.012497  ...  16.546875   88.5000  30.375000  55.87500   \n",
      "25756  0.000000  0.000000  ...  21.406250   97.7500  54.000000  81.75000   \n",
      "...         ...       ...  ...        ...       ...        ...       ...   \n",
      "4      0.000000  0.000000  ...  13.031250   93.6875  35.156250  72.50000   \n",
      "3      3.000000  0.125000  ...  19.062500  100.0000  31.078125  72.56250   \n",
      "2      0.000000  0.000000  ...  16.109375   99.3750  38.625000  74.81250   \n",
      "1      0.000000  0.000000  ...   7.578125   83.0625  41.500000  60.00000   \n",
      "0      0.000000  0.000000  ...  27.359375   96.6875  56.718750  79.43750   \n",
      "\n",
      "       4748  4749       4750      4751       4752      4753  \n",
      "25760   0.0   0.0  22.171875   97.2500  45.406250  76.81250  \n",
      "25759   0.0   0.0  13.460938   94.4375  38.281250  61.15625  \n",
      "25758   0.0   0.0  26.734375  100.0000  46.156250  75.18750  \n",
      "25757   0.0   0.0  16.515625   88.3125  30.078125  55.40625  \n",
      "25756   0.0   0.0  21.406250   97.8750  54.000000  81.68750  \n",
      "...     ...   ...        ...       ...        ...       ...  \n",
      "4       0.0   0.0  13.351562   93.8125  37.468750  73.37500  \n",
      "3       0.0   0.0  19.062500  100.0000  30.046875  72.31250  \n",
      "2       0.0   0.0  16.500000   99.2500  38.750000  74.75000  \n",
      "1       0.0   0.0   7.460938   83.8125  42.750000  60.50000  \n",
      "0       0.0   0.0  27.296875   96.7500  56.750000  79.50000  \n",
      "\n",
      "[25761 rows x 4682 columns]\n",
      "72312003870\n",
      "\\\\CXA01\\Users\\jhugh\\Documents\\Py_S4\\NCEI_parquet_files\\prec_s4data_DAY_SUMMARY_72312003870_stations_1_RowMn_180_ColDy_30.parquet\n",
      "(128807, 4682)\n",
      "All records at start (128806, 4682)\n",
      "First missing values dropped (128806, 4682)\n",
      "[-inf, 0.1, 0.5, 1, 2, 3, 4, 5, inf] [0, 0.1, 0.5, 1, 2, 3, 4, 5]\n",
      "Analysis Set: (128806, 4682)\n",
      "tgt_bin\n",
      "0.0    86844\n",
      "0.1     4539\n",
      "0.5     2880\n",
      "1.0     4222\n",
      "2.0     2480\n",
      "3.0     1565\n",
      "4.0     1473\n",
      "5.0    24803\n",
      "Name: count, dtype: int64\n",
      "Training Set: (77284, 4682)\n",
      "tgt_bin\n",
      "0.0    52127\n",
      "0.1     2727\n",
      "0.5     1695\n",
      "1.0     2560\n",
      "2.0     1489\n",
      "3.0      932\n",
      "4.0      902\n",
      "5.0    14852\n",
      "Name: count, dtype: int64\n",
      "Validation Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    17348\n",
      "0.1      942\n",
      "0.5      582\n",
      "1.0      807\n",
      "2.0      532\n",
      "3.0      316\n",
      "4.0      272\n",
      "5.0     4962\n",
      "Name: count, dtype: int64\n",
      "Test Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    17369\n",
      "0.1      870\n",
      "0.5      603\n",
      "1.0      855\n",
      "2.0      459\n",
      "3.0      317\n",
      "4.0      299\n",
      "5.0     4989\n",
      "Name: count, dtype: int64\n",
      "Datasets exported successfully.\n",
      "Done with       tgt_bin   0   1        75         76        77         78        79  \\\n",
      "25760     0.0   6  23  0.000000  27.859375   78.9375  31.328125  50.15625   \n",
      "25759     0.0   3   1  0.441650  11.890625   90.0000  65.187500  81.68750   \n",
      "25758     1.0   8   8  0.000000  28.515625   97.0000  46.843750  70.00000   \n",
      "25757     0.0   5  11  0.000000  22.281250   80.5625  34.468750  55.25000   \n",
      "25756     0.0   2  10  0.000000  13.039062   92.6875  64.687500  82.56250   \n",
      "...       ...  ..  ..       ...        ...       ...        ...       ...   \n",
      "4         5.0  12  19  0.320801  14.156250   97.8750  84.500000  93.43750   \n",
      "3         5.0   7   3  0.904297  24.406250  100.0000  60.125000  84.12500   \n",
      "2         5.0   2  16  0.300049  12.507812   93.6875  66.812500  83.50000   \n",
      "1         0.0   4   3  0.000000  20.125000   89.2500  52.375000  70.62500   \n",
      "0         5.0   6   7  0.000000  21.093750   93.8125  46.625000  74.81250   \n",
      "\n",
      "              80        81  ...       4744     4745       4746      4747  \\\n",
      "25760   0.000000  0.000000  ...  14.484375  97.0000  86.312500  92.06250   \n",
      "25759  20.500000  0.854004  ...   7.250000  54.5000  24.125000  41.62500   \n",
      "25758   0.000000  0.000000  ...  26.437500  95.1875  46.156250  70.68750   \n",
      "25757   0.000000  0.000000  ...  20.359375  83.4375  35.000000  58.09375   \n",
      "25756   0.000000  0.000000  ...  11.609375  93.0000  56.000000  83.50000   \n",
      "...          ...       ...  ...        ...      ...        ...       ...   \n",
      "4       3.800781  0.158325  ...  15.070312  97.0000  73.000000  87.00000   \n",
      "3      21.703125  0.904297  ...  26.328125  97.0000  56.718750  76.37500   \n",
      "2       7.199219  0.300049  ...   4.949219  83.2500  25.750000  50.00000   \n",
      "1       0.000000  0.000000  ...  14.437500  66.4375  16.296875  34.15625   \n",
      "0       0.000000  0.000000  ...  14.328125  86.5000  37.000000  58.50000   \n",
      "\n",
      "            4748      4749       4750     4751       4752      4753  \n",
      "25760  31.296875  1.303711  14.546875  97.0000  86.000000  92.00000  \n",
      "25759   0.000000  0.000000   7.386719  54.0000  24.078125  41.40625  \n",
      "25758   0.000000  0.000000  26.515625  95.2500  46.250000  71.00000  \n",
      "25757   0.000000  0.000000  20.312500  83.5000  35.000000  58.00000  \n",
      "25756   1.299805  0.054169  11.468750  93.0000  56.156250  83.81250  \n",
      "...          ...       ...        ...      ...        ...       ...  \n",
      "4       0.000000  0.000000  15.117188  97.0000  73.000000  87.00000  \n",
      "3       0.000000  0.000000  26.312500  97.0000  57.156250  76.50000  \n",
      "2       0.000000  0.000000   4.921875  82.9375  25.875000  50.15625  \n",
      "1       0.000000  0.000000  14.507812  66.1875  15.835938  33.34375  \n",
      "0       0.000000  0.000000  14.328125  87.6875  36.656250  58.65625  \n",
      "\n",
      "[25761 rows x 4682 columns]\n",
      "72417013729\n",
      "\\\\CXA01\\Users\\jhugh\\Documents\\Py_S4\\NCEI_parquet_files\\prec_s4data_DAY_SUMMARY_72417013729_stations_1_RowMn_180_ColDy_30.parquet\n",
      "(128807, 4682)\n",
      "All records at start (128806, 4682)\n",
      "First missing values dropped (128806, 4682)\n",
      "[-inf, 0.1, 0.5, 1, 2, 3, 4, 5, inf] [0, 0.1, 0.5, 1, 2, 3, 4, 5]\n",
      "Analysis Set: (128806, 4682)\n",
      "tgt_bin\n",
      "0.0    67644\n",
      "0.1     6464\n",
      "0.5     5004\n",
      "1.0     5922\n",
      "2.0     4369\n",
      "3.0     3616\n",
      "4.0     2802\n",
      "5.0    32985\n",
      "Name: count, dtype: int64\n",
      "Training Set: (77284, 4682)\n",
      "tgt_bin\n",
      "0.0    40411\n",
      "0.1     3845\n",
      "0.5     3007\n",
      "1.0     3558\n",
      "2.0     2655\n",
      "3.0     2199\n",
      "4.0     1707\n",
      "5.0    19902\n",
      "Name: count, dtype: int64\n",
      "Validation Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    13621\n",
      "0.1     1288\n",
      "0.5      995\n",
      "1.0     1169\n",
      "2.0      873\n",
      "3.0      694\n",
      "4.0      557\n",
      "5.0     6564\n",
      "Name: count, dtype: int64\n",
      "Test Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    13612\n",
      "0.1     1331\n",
      "0.5     1002\n",
      "1.0     1195\n",
      "2.0      841\n",
      "3.0      723\n",
      "4.0      538\n",
      "5.0     6519\n",
      "Name: count, dtype: int64\n",
      "Datasets exported successfully.\n",
      "Done with       tgt_bin   0   1        75         76       77         78       79  \\\n",
      "25760     0.0   7  17  0.000000  20.625000  97.6250  32.843750  67.6250   \n",
      "25759     0.0   7  20  0.000000  22.125000  98.0000  45.656250  77.3125   \n",
      "25758     0.0   5   4  0.470947  17.265625  97.0000  69.312500  88.0000   \n",
      "25757     0.0   5  13  0.000000  16.140625  99.5625  37.718750  68.3125   \n",
      "25756     0.0   5  13  0.000000   8.968750  93.1875  38.500000  64.7500   \n",
      "...       ...  ..  ..       ...        ...      ...        ...      ...   \n",
      "4         5.0   7  18  1.253906  21.921875  97.0000  62.500000  81.2500   \n",
      "3         5.0  11   7  1.133789   2.636719      NaN        NaN      NaN   \n",
      "2         0.0  11  19  0.000000   9.273438  94.1875  31.671875  72.3750   \n",
      "1         5.0   6  10  4.351562  20.468750  92.7500  41.906250  70.0625   \n",
      "0         5.0   1   8  0.175049   1.168945  87.6875  50.843750  68.0000   \n",
      "\n",
      "               80        81  ...       4744     4745      4746     4747  \\\n",
      "25760    0.000000  0.000000  ...  20.031250  99.3750  58.75000  82.0000   \n",
      "25759    0.000000  0.000000  ...  19.843750  97.0000  54.59375  78.9375   \n",
      "25758   11.296875  0.470947  ...  11.343750  93.7500  22.00000  59.7500   \n",
      "25757    0.000000  0.000000  ...   3.343750  82.3750  42.62500  61.8750   \n",
      "25756    0.000000  0.000000  ...  14.562500  84.6250  17.62500  47.8750   \n",
      "...           ...       ...  ...        ...      ...       ...      ...   \n",
      "4       30.093750  1.253906  ...  25.875000  96.0000  53.15625  78.1875   \n",
      "3       27.406250  1.141602  ...   9.601562      NaN       NaN      NaN   \n",
      "2        0.000000  0.000000  ...  15.781250      NaN       NaN      NaN   \n",
      "1      104.125000  4.335938  ...  15.953125  91.5000  32.50000  63.0000   \n",
      "0        4.199219  0.175049  ...  10.531250  90.6875  36.15625  67.7500   \n",
      "\n",
      "            4748      4749       4750     4751       4752      4753  \n",
      "25760   0.000000  0.000000  19.859375  99.2500  58.500000  82.00000  \n",
      "25759   0.000000  0.000000  19.937500  97.0000  54.375000  78.87500  \n",
      "25758   0.000000  0.000000  10.906250  93.6250  22.828125  60.12500  \n",
      "25757   0.000000  0.000000   3.277344  82.0625  43.593750  62.09375  \n",
      "25756   0.000000  0.000000  14.257812  84.2500  17.578125  47.40625  \n",
      "...          ...       ...        ...      ...        ...       ...  \n",
      "4       0.000000  0.000000  25.921875  96.0000  53.968750  78.68750  \n",
      "3       0.000000  0.000000   9.484375      NaN        NaN       NaN  \n",
      "2       0.000000  0.000000  15.710938      NaN        NaN       NaN  \n",
      "1      47.000000  1.958008  16.109375  91.6250  31.703125  62.34375  \n",
      "0       4.898438  0.204224  10.484375  90.5000  34.750000  67.37500  \n",
      "\n",
      "[25761 rows x 4682 columns]\n",
      "72438093819\n",
      "\\\\CXA01\\Users\\jhugh\\Documents\\Py_S4\\NCEI_parquet_files\\prec_s4data_DAY_SUMMARY_72438093819_stations_1_RowMn_180_ColDy_30.parquet\n",
      "(128807, 4682)\n",
      "All records at start (128806, 4682)\n",
      "First missing values dropped (128806, 4682)\n",
      "[-inf, 0.1, 0.5, 1, 2, 3, 4, 5, inf] [0, 0.1, 0.5, 1, 2, 3, 4, 5]\n",
      "Analysis Set: (128806, 4682)\n",
      "tgt_bin\n",
      "0.0    84217\n",
      "0.1     4967\n",
      "0.5     3701\n",
      "1.0     4744\n",
      "2.0     3170\n",
      "3.0     2539\n",
      "4.0     2026\n",
      "5.0    23442\n",
      "Name: count, dtype: int64\n",
      "Training Set: (77284, 4682)\n",
      "tgt_bin\n",
      "0.0    50306\n",
      "0.1     3077\n",
      "0.5     2180\n",
      "1.0     2862\n",
      "2.0     1959\n",
      "3.0     1537\n",
      "4.0     1220\n",
      "5.0    14143\n",
      "Name: count, dtype: int64\n",
      "Validation Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    17106\n",
      "0.1      932\n",
      "0.5      723\n",
      "1.0      965\n",
      "2.0      590\n",
      "3.0      492\n",
      "4.0      392\n",
      "5.0     4561\n",
      "Name: count, dtype: int64\n",
      "Test Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    16805\n",
      "0.1      958\n",
      "0.5      798\n",
      "1.0      917\n",
      "2.0      621\n",
      "3.0      510\n",
      "4.0      414\n",
      "5.0     4738\n",
      "Name: count, dtype: int64\n",
      "Datasets exported successfully.\n",
      "Done with       tgt_bin   0   1        75         76       77        78        79  \\\n",
      "25760     5.0   5  19  0.000000  19.203125  79.8125  32.00000  50.40625   \n",
      "25759     0.0   5  22  0.000000  22.109375  95.8125  38.65625  67.75000   \n",
      "25758     5.0   4  12  0.799805  15.726562  97.0000  80.00000  92.00000   \n",
      "25757     0.0   9  11  0.000000  26.687500  90.1250  50.40625  69.93750   \n",
      "25756     5.0   5  16  0.220825  18.609375  93.6875  54.00000  78.68750   \n",
      "...       ...  ..  ..       ...        ...      ...       ...       ...   \n",
      "4         0.5   3   9  0.125000  15.179688  65.5000  31.12500  46.00000   \n",
      "3         5.0   1   2  1.608398   3.601562  80.6875  48.15625  61.15625   \n",
      "2         5.0  11  19  0.012497  11.976562      NaN       NaN       NaN   \n",
      "1         5.0   1  13  0.975098   5.496094  82.6250  42.65625  62.96875   \n",
      "0         0.0   8  14  0.020828  23.750000  81.8125  59.84375  72.68750   \n",
      "\n",
      "              80        81  ...       4744      4745       4746      4747  \\\n",
      "25760   0.000000  0.000000  ...  10.343750   65.8750  37.125000  50.50000   \n",
      "25759   0.000000  0.000000  ...  10.718750   61.0000  21.000000  36.00000   \n",
      "25758  19.203125  0.799805  ...  11.312500   83.1875  31.078125  58.90625   \n",
      "25757   0.000000  0.000000  ...  24.109375  100.0000  67.375000  84.43750   \n",
      "25756   5.300781  0.220825  ...   2.830078   77.5000  40.750000  60.75000   \n",
      "...          ...       ...  ...        ...       ...        ...       ...   \n",
      "4       3.000000  0.125000  ...   0.303467   93.8125  70.000000  81.37500   \n",
      "3      36.812500  1.533203  ...   3.470703   97.5000  62.000000  81.50000   \n",
      "2       0.000000  0.000000  ...  14.492188       NaN        NaN       NaN   \n",
      "1      21.406250  0.891602  ...  -3.558594   85.0000  62.875000  74.37500   \n",
      "0       0.500000  0.020828  ...  16.500000   89.3125  52.656250  73.00000   \n",
      "\n",
      "           4748      4749       4750       4751       4752      4753  \n",
      "25760  0.000000  0.000000  10.179688   66.81250  36.843750  50.65625  \n",
      "25759  0.000000  0.000000  10.703125   62.03125  21.421875  36.78125  \n",
      "25758  3.500000  0.145874  12.007812   82.56250  32.281250  59.21875  \n",
      "25757  0.000000  0.000000  24.140625  100.00000  68.500000  85.00000  \n",
      "25756  0.000000  0.000000   2.478516   77.93750  41.531250  61.71875  \n",
      "...         ...       ...        ...        ...        ...       ...  \n",
      "4      1.799805  0.075012   0.428467   93.68750  70.000000  81.25000  \n",
      "3      4.199219  0.175049   3.724609   97.37500  61.000000  81.12500  \n",
      "2      0.000000  0.000000  14.476562        NaN        NaN       NaN  \n",
      "1      0.000000  0.000000  -3.232422   85.00000  62.093750  74.06250  \n",
      "0      0.000000  0.000000  16.375000   90.00000  52.750000  73.50000  \n",
      "\n",
      "[25761 rows x 4682 columns]\n",
      "72515004725\n",
      "\\\\CXA01\\Users\\jhugh\\Documents\\Py_S4\\NCEI_parquet_files\\prec_s4data_DAY_SUMMARY_72515004725_stations_1_RowMn_180_ColDy_30.parquet\n",
      "(128807, 4682)\n",
      "All records at start (128806, 4682)\n",
      "First missing values dropped (128806, 4682)\n",
      "[-inf, 0.1, 0.5, 1, 2, 3, 4, 5, inf] [0, 0.1, 0.5, 1, 2, 3, 4, 5]\n",
      "Analysis Set: (128806, 4682)\n",
      "tgt_bin\n",
      "0.0    68436\n",
      "0.1     8051\n",
      "0.5     5475\n",
      "1.0     6916\n",
      "2.0     4496\n",
      "3.0     3172\n",
      "4.0     2586\n",
      "5.0    29674\n",
      "Name: count, dtype: int64\n",
      "Training Set: (77284, 4682)\n",
      "tgt_bin\n",
      "0.0    41135\n",
      "0.1     4808\n",
      "0.5     3248\n",
      "1.0     4151\n",
      "2.0     2721\n",
      "3.0     1899\n",
      "4.0     1555\n",
      "5.0    17767\n",
      "Name: count, dtype: int64\n",
      "Validation Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    13683\n",
      "0.1     1607\n",
      "0.5     1076\n",
      "1.0     1410\n",
      "2.0      856\n",
      "3.0      642\n",
      "4.0      527\n",
      "5.0     5960\n",
      "Name: count, dtype: int64\n",
      "Test Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    13618\n",
      "0.1     1636\n",
      "0.5     1151\n",
      "1.0     1355\n",
      "2.0      919\n",
      "3.0      631\n",
      "4.0      504\n",
      "5.0     5947\n",
      "Name: count, dtype: int64\n",
      "Datasets exported successfully.\n",
      "Done with       tgt_bin   0   1        75         76       77         78        79  \\\n",
      "25760     2.0  10  23  0.024994  19.656250  98.1875  76.562500  88.18750   \n",
      "25759     0.0   6  11  0.000000  19.843750  90.1250  54.156250  70.50000   \n",
      "25758     0.0   3  15  0.000000   0.320801  99.5000  80.875000  89.12500   \n",
      "25757     0.0   9  16  0.000000  17.000000  94.6875  45.000000  69.00000   \n",
      "25756     4.0   7  20  0.000000  25.187500  78.0000  31.328125  50.00000   \n",
      "...       ...  ..  ..       ...        ...      ...        ...       ...   \n",
      "4         0.0   6   7  0.000000  18.828125  91.7500  44.656250  64.68750   \n",
      "3         1.0  10  20  0.000000   1.283203  96.6875  82.000000  89.31250   \n",
      "2         0.0   9  16  0.000000  15.117188  88.5000  41.500000  62.65625   \n",
      "1         0.0   5  11  0.000000  15.648438  97.0000  48.281250  75.31250   \n",
      "0         0.5   2  13  0.120850   0.541504  92.0625  25.750000  59.96875   \n",
      "\n",
      "             80        81  ...       4744     4745      4746      4747  \\\n",
      "25760  0.600098  0.024994  ...  22.531250  75.3750  35.90625  55.15625   \n",
      "25759  0.000000  0.000000  ...  16.406250  79.3125  32.87500  52.34375   \n",
      "25758  0.000000  0.000000  ...  -9.296875  97.1875  65.18750  78.56250   \n",
      "25757  0.000000  0.000000  ...  22.093750  99.0000  55.75000  86.25000   \n",
      "25756  0.000000  0.000000  ...  15.742188  96.6875  69.43750  84.50000   \n",
      "...         ...       ...  ...        ...      ...       ...       ...   \n",
      "4      0.000000  0.000000  ...  18.078125  73.2500  28.25000  46.50000   \n",
      "3      0.000000  0.000000  ...  19.328125  97.2500  50.09375  70.31250   \n",
      "2      0.000000  0.000000  ...  18.359375  88.5000  43.25000  63.00000   \n",
      "1      0.000000  0.000000  ...   4.183594  88.6875  43.96875  61.09375   \n",
      "0      2.300781  0.095825  ...   2.681641  77.8750  45.62500  64.50000   \n",
      "\n",
      "            4748      4749       4750     4751      4752      4753  \n",
      "25760   0.000000  0.000000  22.734375  75.0000  36.00000  55.00000  \n",
      "25759   0.500000  0.020828  16.125000  79.5000  32.50000  52.00000  \n",
      "25758   0.000000  0.000000  -9.250000  97.3125  66.31250  79.31250  \n",
      "25757  15.203125  0.633301  21.921875  98.8125  55.03125  86.31250  \n",
      "25756   0.000000  0.000000  15.250000  96.5000  69.12500  84.25000  \n",
      "...          ...       ...        ...      ...       ...       ...  \n",
      "4       0.600098  0.024994  18.125000  73.3125  28.00000  46.34375  \n",
      "3       0.000000  0.000000  19.375000  97.3750  51.12500  71.00000  \n",
      "2       0.000000  0.000000  18.406250  88.4375  43.28125  63.00000  \n",
      "1       0.000000  0.000000   4.082031  89.0000  45.50000  62.00000  \n",
      "0       0.000000  0.000000   2.662109  78.0625  45.59375  64.31250  \n",
      "\n",
      "[25761 rows x 4682 columns]\n",
      "72519014771\n",
      "\\\\CXA01\\Users\\jhugh\\Documents\\Py_S4\\NCEI_parquet_files\\prec_s4data_DAY_SUMMARY_72519014771_stations_1_RowMn_180_ColDy_30.parquet\n",
      "(128807, 4682)\n",
      "All records at start (128806, 4682)\n",
      "First missing values dropped (128806, 4682)\n",
      "[-inf, 0.1, 0.5, 1, 2, 3, 4, 5, inf] [0, 0.1, 0.5, 1, 2, 3, 4, 5]\n",
      "Analysis Set: (128806, 4682)\n",
      "tgt_bin\n",
      "0.0    67617\n",
      "0.1     7740\n",
      "0.5     5881\n",
      "1.0     7759\n",
      "2.0     5223\n",
      "3.0     3639\n",
      "4.0     3335\n",
      "5.0    27612\n",
      "Name: count, dtype: int64\n",
      "Training Set: (77284, 4682)\n",
      "tgt_bin\n",
      "0.0    40667\n",
      "0.1     4662\n",
      "0.5     3566\n",
      "1.0     4607\n",
      "2.0     3057\n",
      "3.0     2158\n",
      "4.0     1974\n",
      "5.0    16593\n",
      "Name: count, dtype: int64\n",
      "Validation Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    13452\n",
      "0.1     1513\n",
      "0.5     1147\n",
      "1.0     1632\n",
      "2.0     1064\n",
      "3.0      742\n",
      "4.0      711\n",
      "5.0     5500\n",
      "Name: count, dtype: int64\n",
      "Test Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    13498\n",
      "0.1     1565\n",
      "0.5     1168\n",
      "1.0     1520\n",
      "2.0     1102\n",
      "3.0      739\n",
      "4.0      650\n",
      "5.0     5519\n",
      "Name: count, dtype: int64\n",
      "Datasets exported successfully.\n",
      "Done with       tgt_bin   0   1        75         76        77        78       79  \\\n",
      "25760     0.1   5  17  0.000000  20.203125   95.3750  52.34375  70.5625   \n",
      "25759     0.0  10  18  0.000000  11.437500       NaN       NaN      NaN   \n",
      "25758     0.0  11  15  0.000000   0.227051       NaN       NaN      NaN   \n",
      "25757     0.0   5  14  0.000000  23.640625   99.4375  46.65625  70.3125   \n",
      "25756     0.1   2   5  0.012497 -11.328125       NaN       NaN      NaN   \n",
      "...       ...  ..  ..       ...        ...       ...       ...      ...   \n",
      "4         0.5   4  20  0.070862   6.082031  100.0000  43.34375  81.0000   \n",
      "3         0.0   1  15  0.000000  -4.253906   91.5000  68.25000  76.5000   \n",
      "2         5.0   1  20  0.000000   0.097900   98.6875  67.31250  80.0000   \n",
      "1         0.0   5  22  0.216675  13.242188   95.3125  50.00000  67.1875   \n",
      "0         5.0  11   5  0.516602   1.212891       NaN       NaN      NaN   \n",
      "\n",
      "              80        81  ...       4744      4745      4746      4747  \\\n",
      "25760   0.000000  0.000000  ...   9.000000   98.5625  57.59375  78.56250   \n",
      "25759   0.000000  0.000000  ...  19.890625   93.0000  65.31250  82.18750   \n",
      "25758   0.000000  0.000000  ...   9.523438       NaN       NaN       NaN   \n",
      "25757   0.000000  0.000000  ...  11.710938  100.0000  57.00000  84.00000   \n",
      "25756   0.300049  0.012497  ...  -9.070312  100.0000  69.43750  85.31250   \n",
      "...          ...       ...  ...        ...       ...       ...       ...   \n",
      "4       1.700195  0.070862  ...  -5.445312   87.0625  32.90625  57.40625   \n",
      "3       0.000000  0.000000  ...   6.000000   84.0625  61.62500  70.81250   \n",
      "2       0.000000  0.000000  ...  11.257812   97.0000  72.93750  82.68750   \n",
      "1       5.199219  0.216675  ...  11.171875   92.0000  51.00000  74.00000   \n",
      "0      12.398438  0.516602  ...  10.898438       NaN       NaN       NaN   \n",
      "\n",
      "            4748      4749       4750      4751      4752     4753  \n",
      "25760   0.000000  0.000000   8.953125   98.2500  57.50000  78.5000  \n",
      "25759   5.000000  0.208374  20.156250   93.0000  65.18750  81.9375  \n",
      "25758   0.000000  0.000000   9.390625       NaN       NaN      NaN  \n",
      "25757   4.300781  0.179199  11.601562  100.0000  57.12500  84.1250  \n",
      "25756   0.000000  0.000000  -8.539062  100.0000  70.25000  86.0000  \n",
      "...          ...       ...        ...       ...       ...      ...  \n",
      "4       0.000000  0.000000  -5.816406   87.1250  33.87500  58.1250  \n",
      "3       0.000000  0.000000   6.234375   83.3125  61.00000  70.3125  \n",
      "2       0.000000  0.000000  10.976562   97.0000  72.37500  82.5000  \n",
      "1      10.898438  0.454102  11.093750   91.6250  50.28125  73.3125  \n",
      "0       0.300049  0.012497  11.101562       NaN       NaN      NaN  \n",
      "\n",
      "[25761 rows x 4682 columns]\n",
      "72605014745\n",
      "\\\\CXA01\\Users\\jhugh\\Documents\\Py_S4\\NCEI_parquet_files\\prec_s4data_DAY_SUMMARY_72605014745_stations_1_RowMn_180_ColDy_30.parquet\n",
      "(128807, 4682)\n",
      "All records at start (128806, 4682)\n",
      "First missing values dropped (128806, 4682)\n",
      "[-inf, 0.1, 0.5, 1, 2, 3, 4, 5, inf] [0, 0.1, 0.5, 1, 2, 3, 4, 5]\n",
      "Analysis Set: (128806, 4682)\n",
      "tgt_bin\n",
      "0.0    82232\n",
      "0.1     5585\n",
      "0.5     3743\n",
      "1.0     4748\n",
      "2.0     2858\n",
      "3.0     2090\n",
      "4.0     2041\n",
      "5.0    25509\n",
      "Name: count, dtype: int64\n",
      "Training Set: (77284, 4682)\n",
      "tgt_bin\n",
      "0.0    49344\n",
      "0.1     3332\n",
      "0.5     2210\n",
      "1.0     2887\n",
      "2.0     1733\n",
      "3.0     1249\n",
      "4.0     1221\n",
      "5.0    15308\n",
      "Name: count, dtype: int64\n",
      "Validation Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    16473\n",
      "0.1     1072\n",
      "0.5      790\n",
      "1.0      917\n",
      "2.0      564\n",
      "3.0      433\n",
      "4.0      402\n",
      "5.0     5110\n",
      "Name: count, dtype: int64\n",
      "Test Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    16415\n",
      "0.1     1181\n",
      "0.5      743\n",
      "1.0      944\n",
      "2.0      561\n",
      "3.0      408\n",
      "4.0      418\n",
      "5.0     5091\n",
      "Name: count, dtype: int64\n",
      "Datasets exported successfully.\n",
      "Done with       tgt_bin   0   1   75         76       77         78        79   80   81  \\\n",
      "25760     0.0  10   5  0.0   8.093750  97.9375  28.671875  68.87500  0.0  0.0   \n",
      "25759     0.0  10  21  0.0  10.531250  98.1250  35.125000  70.12500  0.0  0.0   \n",
      "25758     0.0   1  22  0.0  -8.140625  67.1875  38.906250  50.15625  0.0  0.0   \n",
      "25757     0.0   7   0  0.0  19.671875  97.0000  44.000000  71.00000  0.0  0.0   \n",
      "25756     0.0   3  16  0.0   3.472656  88.3125  45.343750  59.50000  0.0  0.0   \n",
      "...       ...  ..  ..  ...        ...      ...        ...       ...  ...  ...   \n",
      "4         0.0   5   5  0.0  10.546875  96.6875  33.625000  60.96875  0.0  0.0   \n",
      "3         1.0  10  16  0.0  16.812500  97.0000  55.156250  80.31250  0.0  0.0   \n",
      "2         0.0   3  11  0.0  -5.214844  78.4375  49.031250  60.87500  0.0  0.0   \n",
      "1         0.0   1   2  0.0  -3.564453  72.0000  43.000000  58.09375  0.0  0.0   \n",
      "0         4.0   9   8  0.0  19.968750  98.8125  54.343750  77.31250  0.0  0.0   \n",
      "\n",
      "       ...       4744      4745      4746      4747       4748      4749  \\\n",
      "25760  ...  15.531250   97.1875  54.75000  81.56250   7.898438  0.329102   \n",
      "25759  ...  19.203125  100.0000  38.87500  68.81250   0.000000  0.000000   \n",
      "25758  ...   0.279053   96.0000  49.00000  74.00000   0.000000  0.000000   \n",
      "25757  ...  19.656250   95.7500  48.40625  72.31250   0.000000  0.000000   \n",
      "25756  ...  -9.179688       NaN       NaN       NaN   0.000000  0.000000   \n",
      "...    ...        ...       ...       ...       ...        ...       ...   \n",
      "4      ...   6.320312   83.1250  17.00000  43.40625   0.000000  0.000000   \n",
      "3      ...  21.265625   94.0000  52.25000  75.75000  19.593750  0.816895   \n",
      "2      ... -10.625000   78.7500  54.90625  65.93750   2.300781  0.095825   \n",
      "1      ...  -2.769531   81.8125  63.00000  67.31250   0.000000  0.000000   \n",
      "0      ...  21.312500   98.7500  38.90625  73.50000   5.101562  0.212524   \n",
      "\n",
      "            4750      4751      4752     4753  \n",
      "25760  15.171875   97.0000  54.50000  81.5000  \n",
      "25759  19.156250  100.0000  39.75000  69.6875  \n",
      "25758   0.395752   95.5625  48.40625  73.3125  \n",
      "25757  19.703125   95.8750  49.21875  73.1875  \n",
      "25756  -9.242188       NaN       NaN      NaN  \n",
      "...          ...       ...       ...      ...  \n",
      "4       5.796875   83.2500  17.00000  43.5000  \n",
      "3      21.296875   94.1875  51.62500  75.5625  \n",
      "2     -10.765625   78.0000  53.00000  64.5000  \n",
      "1      -2.712891   81.8750  63.00000  67.2500  \n",
      "0      21.437500   98.8750  39.12500  73.7500  \n",
      "\n",
      "[25761 rows x 4682 columns]\n",
      "72635094860\n",
      "\\\\CXA01\\Users\\jhugh\\Documents\\Py_S4\\NCEI_parquet_files\\prec_s4data_DAY_SUMMARY_72635094860_stations_1_RowMn_180_ColDy_30.parquet\n",
      "(128807, 4682)\n",
      "All records at start (128806, 4682)\n",
      "First missing values dropped (128806, 4682)\n",
      "[-inf, 0.1, 0.5, 1, 2, 3, 4, 5, inf] [0, 0.1, 0.5, 1, 2, 3, 4, 5]\n",
      "Analysis Set: (128806, 4682)\n",
      "tgt_bin\n",
      "0.0    78056\n",
      "0.1     6549\n",
      "0.5     5047\n",
      "1.0     6406\n",
      "2.0     3912\n",
      "3.0     2909\n",
      "4.0     2386\n",
      "5.0    23541\n",
      "Name: count, dtype: int64\n",
      "Training Set: (77284, 4682)\n",
      "tgt_bin\n",
      "0.0    46853\n",
      "0.1     3976\n",
      "0.5     2999\n",
      "1.0     3837\n",
      "2.0     2392\n",
      "3.0     1752\n",
      "4.0     1412\n",
      "5.0    14063\n",
      "Name: count, dtype: int64\n",
      "Validation Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    15664\n",
      "0.1     1271\n",
      "0.5     1023\n",
      "1.0     1268\n",
      "2.0      773\n",
      "3.0      591\n",
      "4.0      447\n",
      "5.0     4724\n",
      "Name: count, dtype: int64\n",
      "Test Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    15539\n",
      "0.1     1302\n",
      "0.5     1025\n",
      "1.0     1301\n",
      "2.0      747\n",
      "3.0      566\n",
      "4.0      527\n",
      "5.0     4754\n",
      "Name: count, dtype: int64\n",
      "Datasets exported successfully.\n",
      "Done with       tgt_bin   0   1        75         76        77        78        79  \\\n",
      "25760     0.0   7   0  0.000000  21.421875   88.5000  56.00000  70.50000   \n",
      "25759     0.0   7  22  0.000000  31.203125   77.7500  35.90625  54.09375   \n",
      "25758     0.0   6  20  0.000000  24.781250   85.0000  31.00000  54.34375   \n",
      "25757     5.0   4   9  1.270508  10.429688   86.0000  44.25000  63.62500   \n",
      "25756     0.0   6  13  0.000000  15.570312   88.8750  39.90625  58.87500   \n",
      "...       ...  ..  ..       ...        ...       ...       ...       ...   \n",
      "4         0.0  11  18  0.000000   4.074219   85.0000  52.75000  67.75000   \n",
      "3         0.0   7  21  0.000000  28.203125   88.1250  29.12500  57.50000   \n",
      "2         1.0   4   2  0.304199   8.906250   88.8125  44.34375  72.43750   \n",
      "1         0.0   9  12  0.000000  21.062500  100.0000  48.00000  76.00000   \n",
      "0         0.0  11  21  0.033325  -7.128906   86.0000  65.62500  75.50000   \n",
      "\n",
      "              80        81  ...       4744     4745       4746      4747  \\\n",
      "25760   0.000000  0.000000  ...  18.218750  96.5625  38.406250  70.06250   \n",
      "25759   0.000000  0.000000  ...  18.703125  90.0000  38.000000  66.00000   \n",
      "25758   0.000000  0.000000  ...   9.429688  75.7500  29.421875  54.34375   \n",
      "25757  30.500000  1.270508  ...   2.875000  97.0000  71.687500  86.68750   \n",
      "25756   0.000000  0.000000  ...  20.187500  75.0000  35.375000  56.37500   \n",
      "...          ...       ...  ...        ...      ...        ...       ...   \n",
      "4       0.000000  0.000000  ...  10.671875  89.6875  35.343750  59.84375   \n",
      "3       0.000000  0.000000  ...  11.273438  77.5625  48.156250  60.65625   \n",
      "2       7.300781  0.304199  ...   3.082031  90.5000  35.656250  64.31250   \n",
      "1       0.000000  0.000000  ...  21.453125  91.7500  43.750000  68.81250   \n",
      "0       1.099609  0.045837  ...  17.156250  90.1250  50.718750  70.06250   \n",
      "\n",
      "            4748      4749       4750     4751      4752      4753  \n",
      "25760   0.000000  0.000000  18.171875  96.8125  38.71875  70.56250  \n",
      "25759   0.000000  0.000000  18.421875  90.1250  39.87500  67.00000  \n",
      "25758   0.000000  0.000000   9.304688  75.6250  30.12500  54.50000  \n",
      "25757   0.000000  0.000000   2.880859  97.0000  71.31250  86.93750  \n",
      "25756   0.000000  0.000000  20.265625  75.0000  35.09375  56.09375  \n",
      "...          ...       ...        ...      ...       ...       ...  \n",
      "4       0.000000  0.000000  10.789062  89.8125  35.65625  60.28125  \n",
      "3       1.099609  0.045837  11.484375  78.1875  47.34375  60.34375  \n",
      "2       0.000000  0.000000   3.136719  91.1250  35.25000  64.50000  \n",
      "1       0.000000  0.000000  21.500000  91.6250  44.12500  68.93750  \n",
      "0      19.406250  0.808105  17.484375  90.2500  50.40625  70.06250  \n",
      "\n",
      "[25761 rows x 4682 columns]\n",
      "72638094814\n",
      "\\\\CXA01\\Users\\jhugh\\Documents\\Py_S4\\NCEI_parquet_files\\prec_s4data_DAY_SUMMARY_72638094814_stations_1_RowMn_180_ColDy_30.parquet\n",
      "(128807, 4682)\n",
      "All records at start (128806, 4682)\n",
      "First missing values dropped (128806, 4682)\n",
      "[-inf, 0.1, 0.5, 1, 2, 3, 4, 5, inf] [0, 0.1, 0.5, 1, 2, 3, 4, 5]\n",
      "Analysis Set: (128806, 4682)\n",
      "tgt_bin\n",
      "0.0    77073\n",
      "0.1     8159\n",
      "0.5     5269\n",
      "1.0     7025\n",
      "2.0     4010\n",
      "3.0     2902\n",
      "4.0     2512\n",
      "5.0    21856\n",
      "Name: count, dtype: int64\n",
      "Training Set: (77284, 4682)\n",
      "tgt_bin\n",
      "0.0    46274\n",
      "0.1     4943\n",
      "0.5     3224\n",
      "1.0     4151\n",
      "2.0     2375\n",
      "3.0     1762\n",
      "4.0     1507\n",
      "5.0    13048\n",
      "Name: count, dtype: int64\n",
      "Validation Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    15508\n",
      "0.1     1597\n",
      "0.5     1001\n",
      "1.0     1421\n",
      "2.0      820\n",
      "3.0      574\n",
      "4.0      506\n",
      "5.0     4334\n",
      "Name: count, dtype: int64\n",
      "Test Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    15291\n",
      "0.1     1619\n",
      "0.5     1044\n",
      "1.0     1453\n",
      "2.0      815\n",
      "3.0      566\n",
      "4.0      499\n",
      "5.0     4474\n",
      "Name: count, dtype: int64\n",
      "Datasets exported successfully.\n",
      "Done with       tgt_bin   0   1        75         76       77         78        79  \\\n",
      "25760     0.0   2   8  0.000000 -16.515625      NaN        NaN       NaN   \n",
      "25759     0.1   2  23  0.020828   3.648438  88.6875  47.906250  67.37500   \n",
      "25758     0.0   6   9  0.075012  17.906250  92.5000  42.625000  67.25000   \n",
      "25757     0.0   8  11  0.000000  16.875000  96.1875  40.531250  67.31250   \n",
      "25756     0.0   7   4  0.258301  18.125000  95.3125  55.656250  76.31250   \n",
      "...       ...  ..  ..       ...        ...      ...        ...       ...   \n",
      "4         0.0   7   6  0.075012  14.406250  96.0000  58.250000  79.00000   \n",
      "3         0.0   4  17  0.354248  12.476562  79.5625  30.203125  54.46875   \n",
      "2         0.0  12  16  0.000000   1.491211  99.5000  86.187500  91.68750   \n",
      "1         0.0  10  19  0.000000   4.003906  85.8125  61.531250  72.81250   \n",
      "0         0.0   8  13  0.000000  21.593750  99.8125  47.656250  74.87500   \n",
      "\n",
      "             80        81  ...       4744      4745      4746      4747  \\\n",
      "25760  0.000000  0.000000  ...  -2.308594   90.2500  66.93750  80.93750   \n",
      "25759  0.500000  0.020828  ...  -3.998047   99.5000  76.56250  89.50000   \n",
      "25758  1.799805  0.075012  ...  18.906250   97.0000  32.78125  57.50000   \n",
      "25757  0.000000  0.000000  ...  19.187500   97.0000  41.71875  63.84375   \n",
      "25756  6.199219  0.258301  ...  24.578125   95.2500  48.75000  71.75000   \n",
      "...         ...       ...  ...        ...       ...       ...       ...   \n",
      "4      1.799805  0.075012  ...  23.437500  100.0000  51.34375  75.68750   \n",
      "3      8.500000  0.354248  ...   9.117188   93.6875  33.84375  65.75000   \n",
      "2      0.000000  0.000000  ...  14.734375   99.2500  51.50000  76.50000   \n",
      "1      0.000000  0.000000  ...  13.039062   93.0000  35.62500  69.37500   \n",
      "0      0.000000  0.000000  ...  19.593750   96.0000  37.87500  64.50000   \n",
      "\n",
      "            4748      4749       4750      4751      4752     4753  \n",
      "25760   1.700195  0.070862  -1.890625   90.1250  66.62500  80.6250  \n",
      "25759   0.000000  0.000000  -3.927734  100.0000  77.00000  90.0000  \n",
      "25758   0.000000  0.000000  18.937500   97.0000  32.09375  57.0000  \n",
      "25757   0.000000  0.000000  19.281250   97.0000  41.50000  64.0000  \n",
      "25756   0.000000  0.000000  24.640625   95.5625  48.28125  71.8125  \n",
      "...          ...       ...        ...       ...       ...      ...  \n",
      "4       0.000000  0.000000  23.296875  100.0000  51.90625  75.8125  \n",
      "3       0.000000  0.000000   9.218750   93.2500  34.00000  65.5000  \n",
      "2      12.703125  0.529297  15.187500   99.1250  51.25000  76.2500  \n",
      "1       0.000000  0.000000  12.976562   93.0000  36.15625  69.5000  \n",
      "0       0.000000  0.000000  19.625000   96.0000  38.75000  65.0000  \n",
      "\n",
      "[25761 rows x 4682 columns]\n",
      "72639094849\n",
      "\\\\CXA01\\Users\\jhugh\\Documents\\Py_S4\\NCEI_parquet_files\\prec_s4data_DAY_SUMMARY_72639094849_stations_1_RowMn_180_ColDy_30.parquet\n",
      "(128807, 4682)\n",
      "All records at start (128806, 4682)\n",
      "First missing values dropped (128806, 4682)\n",
      "[-inf, 0.1, 0.5, 1, 2, 3, 4, 5, inf] [0, 0.1, 0.5, 1, 2, 3, 4, 5]\n",
      "Analysis Set: (128806, 4682)\n",
      "tgt_bin\n",
      "0.0    76550\n",
      "0.1     8637\n",
      "0.5     5295\n",
      "1.0     6740\n",
      "2.0     4307\n",
      "3.0     3284\n",
      "4.0     2329\n",
      "5.0    21664\n",
      "Name: count, dtype: int64\n",
      "Training Set: (77284, 4682)\n",
      "tgt_bin\n",
      "0.0    45874\n",
      "0.1     5230\n",
      "0.5     3155\n",
      "1.0     4021\n",
      "2.0     2613\n",
      "3.0     1968\n",
      "4.0     1385\n",
      "5.0    13038\n",
      "Name: count, dtype: int64\n",
      "Validation Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    15348\n",
      "0.1     1658\n",
      "0.5     1128\n",
      "1.0     1329\n",
      "2.0      844\n",
      "3.0      632\n",
      "4.0      475\n",
      "5.0     4347\n",
      "Name: count, dtype: int64\n",
      "Test Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    15328\n",
      "0.1     1749\n",
      "0.5     1012\n",
      "1.0     1390\n",
      "2.0      850\n",
      "3.0      684\n",
      "4.0      469\n",
      "5.0     4279\n",
      "Name: count, dtype: int64\n",
      "Datasets exported successfully.\n",
      "Done with       tgt_bin   0   1        75         76       77         78        79  \\\n",
      "25760     0.0   7  14  0.000000  18.015625  93.0000  36.000000  64.00000   \n",
      "25759     0.0   4   0  0.000000   0.045837  86.5000  41.000000  64.50000   \n",
      "25758     5.0   1  13  0.166626   2.851562  97.1250  89.187500  95.93750   \n",
      "25757     0.0   8  10  0.000000  19.062500  97.0000  40.843750  69.93750   \n",
      "25756     0.5   8  18  0.020828  17.968750  97.7500  51.000000  77.25000   \n",
      "...       ...  ..  ..       ...        ...      ...        ...       ...   \n",
      "4         0.0   8   2  0.000000  19.765625  98.3125  63.750000  83.18750   \n",
      "3         0.1   2  22  0.000000  -8.468750  95.0000  69.812500  85.68750   \n",
      "2         0.0   5  10  0.000000  13.031250  96.9375  19.578125  56.59375   \n",
      "1         1.0   2  19  0.000000 -10.406250  89.6875  60.468750  78.68750   \n",
      "0         4.0  10   7  0.000000  18.328125  97.0000  34.625000  66.18750   \n",
      "\n",
      "             80        81  ...       4744      4745      4746      4747  \\\n",
      "25760  0.000000  0.000000  ...  24.125000   91.3125  50.34375  71.68750   \n",
      "25759  0.000000  0.000000  ...  -5.734375   73.6875  49.59375  58.84375   \n",
      "25758  3.500000  0.145874  ...  -0.027771   84.1250  59.25000  72.37500   \n",
      "25757  0.000000  0.000000  ...  25.078125   93.5000  48.00000  71.00000   \n",
      "25756  1.799805  0.075012  ...  20.187500   96.1875  59.00000  76.31250   \n",
      "...         ...       ...  ...        ...       ...       ...       ...   \n",
      "4      0.000000  0.000000  ...  19.703125   98.3125  48.15625  72.68750   \n",
      "3      0.000000  0.000000  ... -13.078125   83.0000  49.00000  71.00000   \n",
      "2      0.000000  0.000000  ...   1.442383   92.0000  30.50000  66.00000   \n",
      "1      0.000000  0.000000  ... -13.585938   89.0000  70.87500  81.50000   \n",
      "0      0.000000  0.000000  ...  17.406250  100.0000  48.62500  78.87500   \n",
      "\n",
      "           4748      4749       4750      4751       4752      4753  \n",
      "25760  0.000000  0.000000  24.343750   91.1250  49.750000  71.25000  \n",
      "25759  0.000000  0.000000  -5.382812   73.3125  50.281250  58.90625  \n",
      "25758  3.300781  0.137451  -0.134033   83.2500  58.500000  71.75000  \n",
      "25757  6.500000  0.270752  25.078125   93.4375  47.750000  70.81250  \n",
      "25756  0.000000  0.000000  20.156250   96.1875  60.250000  77.18750  \n",
      "...         ...       ...        ...       ...        ...       ...  \n",
      "4      0.000000  0.000000  19.937500   98.7500  49.125000  73.75000  \n",
      "3      0.000000  0.000000 -12.984375   82.6250  49.093750  70.62500  \n",
      "2      1.000000  0.041656   1.398438   92.3125  29.953125  65.93750  \n",
      "1      0.000000  0.000000 -13.765625   89.3125  71.187500  81.68750  \n",
      "0      0.000000  0.000000  16.937500  100.0000  47.343750  78.31250  \n",
      "\n",
      "[25761 rows x 4682 columns]\n",
      "72654014936\n",
      "\\\\CXA01\\Users\\jhugh\\Documents\\Py_S4\\NCEI_parquet_files\\prec_s4data_DAY_SUMMARY_72654014936_stations_1_RowMn_180_ColDy_30.parquet\n",
      "(128807, 4682)\n",
      "All records at start (128806, 4682)\n",
      "First missing values dropped (128806, 4682)\n",
      "[-inf, 0.1, 0.5, 1, 2, 3, 4, 5, inf] [0, 0.1, 0.5, 1, 2, 3, 4, 5]\n",
      "Analysis Set: (128806, 4682)\n",
      "tgt_bin\n",
      "0.0    95637\n",
      "0.1     5956\n",
      "0.5     3819\n",
      "1.0     4616\n",
      "2.0     2605\n",
      "3.0     1890\n",
      "4.0     1207\n",
      "5.0    13076\n",
      "Name: count, dtype: int64\n",
      "Training Set: (77284, 4682)\n",
      "tgt_bin\n",
      "0.0    57470\n",
      "0.1     3614\n",
      "0.5     2228\n",
      "1.0     2783\n",
      "2.0     1531\n",
      "3.0     1133\n",
      "4.0      726\n",
      "5.0     7799\n",
      "Name: count, dtype: int64\n",
      "Validation Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    19092\n",
      "0.1     1196\n",
      "0.5      775\n",
      "1.0      946\n",
      "2.0      555\n",
      "3.0      376\n",
      "4.0      211\n",
      "5.0     2610\n",
      "Name: count, dtype: int64\n",
      "Test Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    19075\n",
      "0.1     1146\n",
      "0.5      816\n",
      "1.0      887\n",
      "2.0      519\n",
      "3.0      381\n",
      "4.0      270\n",
      "5.0     2667\n",
      "Name: count, dtype: int64\n",
      "Datasets exported successfully.\n",
      "Done with       tgt_bin   0   1        75         76       77         78        79  \\\n",
      "25760     0.0   4   2  0.000000  16.203125  85.0000  17.328125  41.90625   \n",
      "25759     5.0  12   3  0.620605  -1.943359      NaN        NaN       NaN   \n",
      "25758     0.0   1  14  0.000000 -13.921875  73.9375  59.656250  67.56250   \n",
      "25757     0.0   6  15  0.000000  26.484375  72.7500  16.500000  43.75000   \n",
      "25756     5.0   2   2  0.629395 -11.164062  89.2500  72.562500  79.00000   \n",
      "...       ...  ..  ..       ...        ...      ...        ...       ...   \n",
      "4         2.0   2   0  0.000000  -1.987305  76.0000  38.500000  55.00000   \n",
      "3         0.0   9   1  0.000000  13.484375  96.5625  39.156250  68.31250   \n",
      "2         0.0   8  10  0.000000  17.437500  90.2500  65.000000  78.31250   \n",
      "1         0.1   5   0  0.000000  15.789062  91.5000  26.500000  50.50000   \n",
      "0         0.1   3  17  0.012497  -8.945312  90.3750  76.562500  84.81250   \n",
      "\n",
      "              80        81  ...       4744     4745       4746      4747  \\\n",
      "25760   0.000000  0.000000  ...  11.585938  90.8125  19.500000  49.65625   \n",
      "25759  15.101562  0.629395  ...   4.453125  88.6250  29.578125  55.37500   \n",
      "25758   0.000000  0.000000  ...  -7.566406  77.6875  48.656250  66.68750   \n",
      "25757   0.000000  0.000000  ...  22.515625  89.6875  28.125000  51.84375   \n",
      "25756  13.796875  0.575195  ... -11.328125  88.0000  75.187500  81.81250   \n",
      "...          ...       ...  ...        ...      ...        ...       ...   \n",
      "4       0.000000  0.000000  ...  -5.316406  72.1875  52.750000  62.50000   \n",
      "3       0.000000  0.000000  ...  22.671875  96.1250  55.000000  71.62500   \n",
      "2       0.000000  0.000000  ...  19.375000  94.5000  50.500000  76.50000   \n",
      "1       0.000000  0.000000  ...  13.695312  81.4375  21.171875  34.75000   \n",
      "0       0.300049  0.012497  ...  -2.421875  96.0000  83.812500  90.56250   \n",
      "\n",
      "            4748      4749       4750     4751       4752      4753  \n",
      "25760   0.000000  0.000000  11.429688  91.1250  19.125000  50.25000  \n",
      "25759   0.000000  0.000000   4.363281  89.5000  29.671875  55.50000  \n",
      "25758   0.000000  0.000000  -7.578125  77.3750  48.375000  66.37500  \n",
      "25757  12.296875  0.512695  22.687500  89.6875  28.000000  51.65625  \n",
      "25756  22.796875  0.950195 -10.875000  88.0000  75.125000  81.87500  \n",
      "...          ...       ...        ...      ...        ...       ...  \n",
      "4       0.000000  0.000000  -5.019531  72.0625  52.375000  62.25000  \n",
      "3      29.703125  1.237305  22.875000  96.0625  55.000000  71.06250  \n",
      "2       0.000000  0.000000  19.359375  94.3750  50.781250  76.43750  \n",
      "1      43.000000  1.791992  14.273438  80.6875  20.078125  32.37500  \n",
      "0       1.099609  0.045837  -2.328125  96.0000  83.000000  90.25000  \n",
      "\n",
      "[25761 rows x 4682 columns]\n",
      "72659014929\n",
      "\\\\CXA01\\Users\\jhugh\\Documents\\Py_S4\\NCEI_parquet_files\\prec_s4data_DAY_SUMMARY_72659014929_stations_1_RowMn_180_ColDy_30.parquet\n",
      "(128807, 4682)\n",
      "All records at start (128806, 4682)\n",
      "First missing values dropped (128806, 4682)\n",
      "[-inf, 0.1, 0.5, 1, 2, 3, 4, 5, inf] [0, 0.1, 0.5, 1, 2, 3, 4, 5]\n",
      "Analysis Set: (128806, 4682)\n",
      "tgt_bin\n",
      "0.0    94441\n",
      "0.1     6123\n",
      "0.5     3701\n",
      "1.0     4783\n",
      "2.0     2562\n",
      "3.0     2061\n",
      "4.0     1558\n",
      "5.0    13577\n",
      "Name: count, dtype: int64\n",
      "Training Set: (77284, 4682)\n",
      "tgt_bin\n",
      "0.0    56599\n",
      "0.1     3664\n",
      "0.5     2210\n",
      "1.0     2893\n",
      "2.0     1570\n",
      "3.0     1275\n",
      "4.0      909\n",
      "5.0     8164\n",
      "Name: count, dtype: int64\n",
      "Validation Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    18983\n",
      "0.1     1271\n",
      "0.5      734\n",
      "1.0      945\n",
      "2.0      487\n",
      "3.0      376\n",
      "4.0      313\n",
      "5.0     2652\n",
      "Name: count, dtype: int64\n",
      "Test Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    18859\n",
      "0.1     1188\n",
      "0.5      757\n",
      "1.0      945\n",
      "2.0      505\n",
      "3.0      410\n",
      "4.0      336\n",
      "5.0     2761\n",
      "Name: count, dtype: int64\n",
      "Datasets exported successfully.\n",
      "Done with       tgt_bin   0   1        75         76       77        78       79  \\\n",
      "25760     0.0   7  17  0.000000  20.875000  91.2500  50.37500  69.0000   \n",
      "25759     0.0   2  22  0.000000 -10.226562  82.6875  65.06250  73.9375   \n",
      "25758     4.0  11  15  0.179199   6.816406  96.1250  50.37500  79.2500   \n",
      "25757     0.0  10  14  0.000000  11.851562      NaN       NaN      NaN   \n",
      "25756     5.0   8   0  5.785156  20.265625  90.0000  70.50000  81.0000   \n",
      "...       ...  ..  ..       ...        ...      ...       ...      ...   \n",
      "4         0.1  10   2  0.012497   3.339844      NaN       NaN      NaN   \n",
      "3         3.0   4  10  0.000000   5.929688  88.1875  33.75000  61.5000   \n",
      "2         0.0   5   5  0.208374  13.984375  92.1250  42.37500  68.5625   \n",
      "1         0.5   4  22  0.183350   7.417969  94.7500  56.40625  75.6875   \n",
      "0         0.0  11  23  0.000000  -2.708984  82.1875  57.37500  68.7500   \n",
      "\n",
      "               80        81  ...       4744      4745       4746      4747  \\\n",
      "25760    0.000000  0.000000  ...  24.765625   94.4375  32.218750  61.25000   \n",
      "25759    0.000000  0.000000  ... -19.406250   78.0000  41.000000  62.00000   \n",
      "25758    2.000000  0.083313  ...  18.734375   82.8125  36.468750  56.12500   \n",
      "25757    0.000000  0.000000  ...  23.046875  100.0000  40.656250  72.00000   \n",
      "25756  137.750000  5.742188  ...  20.671875   90.2500  37.500000  62.84375   \n",
      "...           ...       ...  ...        ...       ...        ...       ...   \n",
      "4        0.300049  0.012497  ...  11.359375   90.5000  29.671875  52.84375   \n",
      "3        0.000000  0.000000  ...   1.810547   92.5000  75.000000  83.00000   \n",
      "2        5.000000  0.208374  ...  12.109375   80.5000  26.296875  48.25000   \n",
      "1        4.398438  0.183350  ...  -5.574219   96.0000  72.000000  80.00000   \n",
      "0        0.000000  0.000000  ...   7.875000   91.8750  32.281250  62.96875   \n",
      "\n",
      "            4748      4749       4750      4751      4752      4753  \n",
      "25760   0.000000  0.000000  24.812500   94.7500  32.25000  61.50000  \n",
      "25759   0.000000  0.000000 -19.687500   78.5625  42.40625  62.65625  \n",
      "25758   0.000000  0.000000  18.875000   82.6875  36.65625  56.00000  \n",
      "25757   0.000000  0.000000  22.921875  100.0000  40.87500  72.37500  \n",
      "25756  66.375000  2.767578  20.671875   90.1250  36.75000  62.40625  \n",
      "...          ...       ...        ...       ...       ...       ...  \n",
      "4       0.000000  0.000000  11.101562   90.3750  29.00000  52.12500  \n",
      "3       0.000000  0.000000   1.850586   92.4375  74.68750  82.68750  \n",
      "2       0.000000  0.000000  12.093750   81.0000  26.25000  48.50000  \n",
      "1       0.300049  0.012497  -5.585938   96.0000  72.00000  80.18750  \n",
      "0       0.000000  0.000000   8.039062   92.0000  32.00000  63.00000  \n",
      "\n",
      "[25761 rows x 4682 columns]\n",
      "72712014607\n",
      "\\\\CXA01\\Users\\jhugh\\Documents\\Py_S4\\NCEI_parquet_files\\prec_s4data_DAY_SUMMARY_72712014607_stations_1_RowMn_180_ColDy_30.parquet\n",
      "(128807, 4682)\n",
      "All records at start (128806, 4682)\n",
      "First missing values dropped (128806, 4682)\n",
      "[-inf, 0.1, 0.5, 1, 2, 3, 4, 5, inf] [0, 0.1, 0.5, 1, 2, 3, 4, 5]\n",
      "Analysis Set: (128806, 4682)\n",
      "tgt_bin\n",
      "0.0    71514\n",
      "0.1     7337\n",
      "0.5     4951\n",
      "1.0     6094\n",
      "2.0     3923\n",
      "3.0     3212\n",
      "4.0     2587\n",
      "5.0    29188\n",
      "Name: count, dtype: int64\n",
      "Training Set: (77284, 4682)\n",
      "tgt_bin\n",
      "0.0    42994\n",
      "0.1     4416\n",
      "0.5     2998\n",
      "1.0     3616\n",
      "2.0     2329\n",
      "3.0     1915\n",
      "4.0     1539\n",
      "5.0    17477\n",
      "Name: count, dtype: int64\n",
      "Validation Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    14225\n",
      "0.1     1469\n",
      "0.5     1008\n",
      "1.0     1217\n",
      "2.0      786\n",
      "3.0      644\n",
      "4.0      509\n",
      "5.0     5903\n",
      "Name: count, dtype: int64\n",
      "Test Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    14295\n",
      "0.1     1452\n",
      "0.5      945\n",
      "1.0     1261\n",
      "2.0      808\n",
      "3.0      653\n",
      "4.0      539\n",
      "5.0     5808\n",
      "Name: count, dtype: int64\n",
      "Datasets exported successfully.\n",
      "Done with       tgt_bin   0   1    75         76        77        78       79  \\\n",
      "25760     0.1   5  23  0.50  10.000000  94.62500  64.12500  81.8750   \n",
      "25759     0.0   2  20  0.00  -4.480469  79.31250  62.00000  71.6875   \n",
      "25758     0.0   9  11  0.00  14.578125  96.06250  53.53125  75.6875   \n",
      "25757     2.0   1  21  0.00 -18.640625  82.62500  60.00000  73.1250   \n",
      "25756     2.0   6  16  0.00  18.187500  94.68750  34.50000  64.5000   \n",
      "...       ...  ..  ..   ...        ...       ...       ...      ...   \n",
      "4         0.0   3  20  0.00 -21.031250  59.34375  34.00000  48.0000   \n",
      "3         0.0  11   2  0.00   5.859375  83.06250  51.00000  67.3125   \n",
      "2         0.0  11   1  0.00  -4.636719  81.62500  61.65625  73.6250   \n",
      "1         5.0   5  19  1.25   7.632812  96.31250  82.68750  90.0000   \n",
      "0         0.0   7   5  0.00  18.890625  93.00000  47.96875  72.0000   \n",
      "\n",
      "              80        81  ...       4744     4745      4746      4747  \\\n",
      "25760  12.000000  0.500000  ...   6.589844  93.0000  45.78125  69.93750   \n",
      "25759   0.000000  0.000000  ... -10.640625  91.7500  70.00000  84.75000   \n",
      "25758   0.000000  0.000000  ...  22.843750  91.6250  37.96875  63.96875   \n",
      "25757   0.000000  0.000000  ...  -3.953125  97.0000  52.28125  77.56250   \n",
      "25756   0.000000  0.000000  ...  19.218750  59.5000  28.50000  43.00000   \n",
      "...          ...       ...  ...        ...      ...       ...       ...   \n",
      "4       0.000000  0.000000  ... -17.156250  87.6875  44.40625  62.50000   \n",
      "3       0.000000  0.000000  ...   7.664062  90.1875  49.15625  64.81250   \n",
      "2       0.000000  0.000000  ...   9.070312  96.5000  75.37500  88.12500   \n",
      "1      31.203125  1.299805  ...   8.273438  74.5000  16.50000  41.75000   \n",
      "0       0.000000  0.000000  ...  11.062500  94.1875  69.12500  89.56250   \n",
      "\n",
      "            4748      4749       4750      4751       4752      4753  \n",
      "25760   7.000000  0.291748   6.484375  93.00000  46.000000  70.00000  \n",
      "25759   1.000000  0.041656 -10.476562  91.62500  70.000000  84.62500  \n",
      "25758  54.687500  2.279297  22.687500  91.50000  37.500000  63.50000  \n",
      "25757   0.000000  0.000000  -3.640625  97.00000  53.593750  78.18750  \n",
      "25756   0.000000  0.000000  19.578125  59.40625  27.921875  42.65625  \n",
      "...          ...       ...        ...       ...        ...       ...  \n",
      "4       0.000000  0.000000 -16.984375  87.50000  45.625000  63.25000  \n",
      "3       0.000000  0.000000   7.906250  90.87500  49.125000  64.87500  \n",
      "2      45.687500  1.904297   9.367188  96.68750  75.562500  88.43750  \n",
      "1       0.600098  0.024994   8.250000  74.68750  16.671875  41.65625  \n",
      "0       8.796875  0.366699  10.859375  94.00000  68.250000  89.50000  \n",
      "\n",
      "[25761 rows x 4682 columns]\n",
      "72734014847\n",
      "\\\\CXA01\\Users\\jhugh\\Documents\\Py_S4\\NCEI_parquet_files\\prec_s4data_DAY_SUMMARY_72734014847_stations_1_RowMn_180_ColDy_30.parquet\n",
      "(128807, 4682)\n",
      "All records at start (128806, 4682)\n",
      "First missing values dropped (128806, 4682)\n",
      "[-inf, 0.1, 0.5, 1, 2, 3, 4, 5, inf] [0, 0.1, 0.5, 1, 2, 3, 4, 5]\n",
      "Analysis Set: (128806, 4682)\n",
      "tgt_bin\n",
      "0.0    69289\n",
      "0.1     6928\n",
      "0.5     5370\n",
      "1.0     7185\n",
      "2.0     4896\n",
      "3.0     3854\n",
      "4.0     3190\n",
      "5.0    28094\n",
      "Name: count, dtype: int64\n",
      "Training Set: (77284, 4682)\n",
      "tgt_bin\n",
      "0.0    41619\n",
      "0.1     4174\n",
      "0.5     3237\n",
      "1.0     4221\n",
      "2.0     2923\n",
      "3.0     2326\n",
      "4.0     1916\n",
      "5.0    16868\n",
      "Name: count, dtype: int64\n",
      "Validation Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    13885\n",
      "0.1     1332\n",
      "0.5     1080\n",
      "1.0     1475\n",
      "2.0     1010\n",
      "3.0      791\n",
      "4.0      613\n",
      "5.0     5575\n",
      "Name: count, dtype: int64\n",
      "Test Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    13785\n",
      "0.1     1422\n",
      "0.5     1053\n",
      "1.0     1489\n",
      "2.0      963\n",
      "3.0      737\n",
      "4.0      661\n",
      "5.0     5651\n",
      "Name: count, dtype: int64\n",
      "Datasets exported successfully.\n",
      "Done with       tgt_bin   0   1        75         76       77        78        79  \\\n",
      "25760     1.0  10   1  0.254150   2.167969  94.3750  69.68750  86.00000   \n",
      "25759     3.0   1   2  0.337402 -16.062500  85.5000  64.93750  75.31250   \n",
      "25758     0.1   5   6  0.291748  13.640625  96.0000  64.75000  81.50000   \n",
      "25757     5.0   9   7  0.641602  18.593750  93.8125  48.00000  75.00000   \n",
      "25756     0.0   9   4  0.000000  15.625000  83.0000  39.65625  63.65625   \n",
      "...       ...  ..  ..       ...        ...      ...       ...       ...   \n",
      "4         1.0   7  11  1.841797  23.125000  93.6875  77.43750  87.12500   \n",
      "3         0.0   2  19  0.000000   0.026382  90.3125  64.81250  75.31250   \n",
      "2         0.0  11  16  0.320801   0.960449  89.0000  59.84375  79.18750   \n",
      "1         0.0   9  20  0.070862  17.578125  91.0000  55.34375  73.68750   \n",
      "0         5.0   4   1  0.254150   6.859375  85.7500  49.03125  69.31250   \n",
      "\n",
      "              80        81  ...       4744    4745      4746      4747  \\\n",
      "25760   8.296875  0.345947  ...  14.312500  88.625  35.37500  67.37500   \n",
      "25759   8.101562  0.337402  ...   0.177124  91.500  68.68750  83.68750   \n",
      "25758   7.000000  0.291748  ...   6.820312  79.000  54.34375  68.00000   \n",
      "25757  14.203125  0.591797  ...  20.093750  93.000  37.12500  66.87500   \n",
      "25756   0.000000  0.000000  ...  17.875000  93.000  64.00000  79.00000   \n",
      "...          ...       ...  ...        ...     ...       ...       ...   \n",
      "4      44.187500  1.841797  ...  19.640625  83.000  35.53125  56.71875   \n",
      "3       0.000000  0.000000  ...   1.367188  98.625  92.62500  95.50000   \n",
      "2       9.898438  0.412598  ...  17.203125  92.250  76.75000  85.25000   \n",
      "1       1.700195  0.070862  ...  23.171875  91.000  69.81250  84.06250   \n",
      "0       4.800781  0.199951  ... -10.867188  91.875  49.00000  69.00000   \n",
      "\n",
      "            4748      4749       4750     4751      4752     4753  \n",
      "25760   0.000000  0.000000  14.242188  88.7500  34.90625  67.2500  \n",
      "25759   0.000000  0.000000   0.254150  91.6250  69.00000  84.0000  \n",
      "25758   0.000000  0.000000   6.773438  79.3750  54.28125  68.2500  \n",
      "25757   0.000000  0.000000  20.046875  93.0000  37.34375  67.0000  \n",
      "25756   0.000000  0.000000  17.937500  93.0000  64.50000  79.3125  \n",
      "...          ...       ...        ...      ...       ...      ...  \n",
      "4       0.000000  0.000000  19.562500  83.0000  35.50000  56.5000  \n",
      "3       3.199219  0.133301   1.328125  98.1875  91.50000  94.6875  \n",
      "2       4.199219  0.175049  17.296875  92.1250  76.06250  84.9375  \n",
      "1      10.101562  0.420898  23.062500  91.0000  70.25000  84.1250  \n",
      "0       0.799805  0.033325 -10.992188  92.2500  49.65625  69.6875  \n",
      "\n",
      "[25761 rows x 4682 columns]\n",
      "72792024227\n",
      "\\\\CXA01\\Users\\jhugh\\Documents\\Py_S4\\NCEI_parquet_files\\prec_s4data_DAY_SUMMARY_72792024227_stations_1_RowMn_180_ColDy_30.parquet\n",
      "(128807, 4682)\n",
      "All records at start (128806, 4682)\n",
      "First missing values dropped (128806, 4682)\n",
      "[-inf, 0.1, 0.5, 1, 2, 3, 4, 5, inf] [0, 0.1, 0.5, 1, 2, 3, 4, 5]\n",
      "Analysis Set: (128806, 4682)\n",
      "tgt_bin\n",
      "0.0    71452\n",
      "0.1     5993\n",
      "0.5     4242\n",
      "1.0     5736\n",
      "2.0     3981\n",
      "3.0     3528\n",
      "4.0     3100\n",
      "5.0    30774\n",
      "Name: count, dtype: int64\n",
      "Training Set: (77284, 4682)\n",
      "tgt_bin\n",
      "0.0    42800\n",
      "0.1     3608\n",
      "0.5     2554\n",
      "1.0     3530\n",
      "2.0     2405\n",
      "3.0     2102\n",
      "4.0     1820\n",
      "5.0    18465\n",
      "Name: count, dtype: int64\n",
      "Validation Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    14371\n",
      "0.1     1187\n",
      "0.5      844\n",
      "1.0     1095\n",
      "2.0      784\n",
      "3.0      729\n",
      "4.0      610\n",
      "5.0     6141\n",
      "Name: count, dtype: int64\n",
      "Test Set: (25761, 4682)\n",
      "tgt_bin\n",
      "0.0    14281\n",
      "0.1     1198\n",
      "0.5      844\n",
      "1.0     1111\n",
      "2.0      792\n",
      "3.0      697\n",
      "4.0      670\n",
      "5.0     6168\n",
      "Name: count, dtype: int64\n",
      "Datasets exported successfully.\n",
      "Done with       tgt_bin   0   1        75         76        77        78       79  \\\n",
      "25760     5.0  12  13  0.170776  -1.878906   96.1875  58.87500  77.6875   \n",
      "25759     5.0   4   6  0.383301  14.625000   94.0000  31.50000  61.0000   \n",
      "25758     0.0   5  16  0.000000  14.289062   96.0000  41.50000  66.3125   \n",
      "25757     0.0   9  16  0.000000  16.718750   99.3125  45.34375  74.1875   \n",
      "25756     0.0   8  17  0.000000  19.687500   90.6250  30.75000  60.0000   \n",
      "...       ...  ..  ..       ...        ...       ...       ...      ...   \n",
      "4         5.0  11   5  0.154175   7.863281   97.8750  73.68750  90.2500   \n",
      "3         0.0   8  10  0.000000  16.265625   96.0625  56.15625  75.0000   \n",
      "2         0.0   9   3  0.000000  16.359375   93.7500  31.12500  58.0000   \n",
      "1         0.0   7  10  0.000000  17.640625   96.0625  41.09375  69.8125   \n",
      "0         5.0   3   6  0.674805   6.457031  100.0000  81.00000  94.2500   \n",
      "\n",
      "              80        81  ...       4744     4745       4746      4747  \\\n",
      "25760   3.300781  0.137451  ...  12.101562  100.000  82.875000  95.62500   \n",
      "25759   9.203125  0.383301  ...   5.578125   95.000  56.000000  77.31250   \n",
      "25758   0.000000  0.000000  ...  11.117188   96.750  46.250000  72.00000   \n",
      "25757   0.000000  0.000000  ...  17.937500   93.000  47.000000  73.25000   \n",
      "25756   0.000000  0.000000  ...  22.937500   87.625  18.828125  51.00000   \n",
      "...          ...       ...  ...        ...      ...        ...       ...   \n",
      "4       4.000000  0.166626  ...   8.023438  100.000  64.937500  92.31250   \n",
      "3       0.000000  0.000000  ...  15.148438   95.000  53.000000  76.50000   \n",
      "2       0.000000  0.000000  ...  21.921875   90.625  24.203125  55.65625   \n",
      "1       0.000000  0.000000  ...  13.914062   93.500  60.500000  76.50000   \n",
      "0      15.203125  0.633301  ...   4.726562   98.000  73.312500  90.68750   \n",
      "\n",
      "            4748      4749       4750      4751       4752      4753  \n",
      "25760  57.312500  2.386719  11.687500  100.0000  81.437500  95.25000  \n",
      "25759  24.093750  1.003906   5.625000   95.1250  55.625000  77.06250  \n",
      "25758   0.000000  0.000000  10.890625   96.6875  47.468750  72.68750  \n",
      "25757   1.000000  0.041656  17.890625   93.0000  46.156250  72.62500  \n",
      "25756   0.000000  0.000000  23.140625   87.7500  19.000000  51.00000  \n",
      "...          ...       ...        ...       ...        ...       ...  \n",
      "4       0.000000  0.000000   8.078125  100.0000  64.500000  92.25000  \n",
      "3       0.000000  0.000000  15.226562   95.1875  53.343750  76.81250  \n",
      "2       0.000000  0.000000  22.078125   90.5000  24.171875  55.34375  \n",
      "1       0.000000  0.000000  13.906250   93.4375  60.718750  76.68750  \n",
      "0       5.199219  0.216675   4.742188   97.8750  73.812500  90.68750  \n",
      "\n",
      "[25761 rows x 4682 columns]\n"
     ]
    }
   ],
   "source": [
    "lst_stx = [\"70200026617\",\"70219026615\",\"70316025624\",\"72202012839\",\"72206013889\",\"72208013880\",\"72214093805\",\"72217003813\",\"72218003820\",\"72223013894\",\"72241012917\",\"72250012919\",\"72251012924\",\"72255012912\",\"72312003870\",\"72417013729\",\"72438093819\",\"72515004725\",\"72519014771\",\"72605014745\",\"72635094860\",\"72638094814\",\"72639094849\",\"72654014936\",\"72659014929\",\"72712014607\",\"72734014847\",\"72792024227\",\"72797094240\"]\n",
    "lst_stx = [\"72218003820\",\"72223013894\",\"72241012917\",\"72250012919\",\"72251012924\",\"72255012912\",\"72312003870\",\"72417013729\",\"72438093819\",\"72515004725\",\"72519014771\",\"72605014745\",\"72635094860\",\"72638094814\",\"72639094849\",\"72654014936\",\"72659014929\",\"72712014607\",\"72734014847\",\"72792024227\"]  #not run all the way to train\n",
    "run_part = 3\n",
    "\n",
    "def process_w_yield(my_list,run_part):\n",
    "    for value in my_list:\n",
    "        yield stid_loop(value,run_part)\n",
    "\n",
    "for result in process_w_yield(lst_stx,run_part):\n",
    "    print(f\"Done with {result}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s4_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
